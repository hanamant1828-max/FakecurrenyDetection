{"file_contents":{"CounterfeitGuard/model.py":{"content":"\"\"\"\nCNN Model for Currency Detection using Transfer Learning with MobileNet\n\"\"\"\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport numpy as np\n\n\ndef create_model(input_shape=(224, 224, 3), num_classes=2):\n    \"\"\"\n    Create CNN model using MobileNetV2 transfer learning\n    \n    Args:\n        input_shape: Input image shape (height, width, channels)\n        num_classes: Number of output classes (2 for genuine/fake)\n    \n    Returns:\n        Compiled Keras model\n    \"\"\"\n    # Load pre-trained MobileNetV2 without top layers\n    base_model = MobileNetV2(\n        input_shape=input_shape,\n        include_top=False,\n        weights='imagenet'\n    )\n    \n    # Freeze base model layers for transfer learning\n    base_model.trainable = False\n    \n    # Build custom classification head\n    inputs = keras.Input(shape=input_shape)\n    \n    # No preprocessing here - it's handled by the data generator\n    # This ensures training and inference use the same preprocessing\n    x = base_model(inputs, training=False)\n    \n    # Global average pooling\n    x = layers.GlobalAveragePooling2D()(x)\n    \n    # Dense layers with dropout for regularization\n    x = layers.Dense(256, activation='relu')(x)\n    x = layers.Dropout(0.5)(x)\n    x = layers.Dense(128, activation='relu')(x)\n    x = layers.Dropout(0.3)(x)\n    \n    # Output layer\n    outputs = layers.Dense(num_classes, activation='softmax')(x)\n    \n    # Create model\n    model = keras.Model(inputs, outputs)\n    \n    # Compile model\n    model.compile(\n        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    \n    return model\n\n\ndef create_data_generators(train_dir, val_dir, batch_size=32, img_size=(224, 224)):\n    \"\"\"\n    Create data generators with augmentation for training and validation\n    \n    Args:\n        train_dir: Directory containing training data\n        val_dir: Directory containing validation data\n        batch_size: Batch size for training\n        img_size: Target image size\n    \n    Returns:\n        train_generator, val_generator\n    \"\"\"\n    # Training data augmentation\n    # Note: No rescaling here - MobileNetV2 preprocessing is applied in the model\n    train_datagen = ImageDataGenerator(\n        preprocessing_function=keras.applications.mobilenet_v2.preprocess_input,\n        rotation_range=20,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        brightness_range=[0.8, 1.2],\n        fill_mode='nearest'\n    )\n    \n    # Validation data (only MobileNetV2 preprocessing)\n    val_datagen = ImageDataGenerator(\n        preprocessing_function=keras.applications.mobilenet_v2.preprocess_input\n    )\n    \n    # Create generators\n    train_generator = train_datagen.flow_from_directory(\n        train_dir,\n        target_size=img_size,\n        batch_size=batch_size,\n        class_mode='categorical'\n    )\n    \n    val_generator = val_datagen.flow_from_directory(\n        val_dir,\n        target_size=img_size,\n        batch_size=batch_size,\n        class_mode='categorical'\n    )\n    \n    return train_generator, val_generator\n\n\ndef preprocess_image(image_path, target_size=(224, 224)):\n    \"\"\"\n    Preprocess single image for prediction\n    \n    Args:\n        image_path: Path to image file\n        target_size: Target size for resizing\n    \n    Returns:\n        Preprocessed image array\n    \"\"\"\n    img = keras.preprocessing.image.load_img(image_path, target_size=target_size)\n    img_array = keras.preprocessing.image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0)\n    img_array = keras.applications.mobilenet_v2.preprocess_input(img_array)\n    return img_array\n\n\ndef fine_tune_model(model, base_model_layers=100):\n    \"\"\"\n    Fine-tune the model by unfreezing top layers\n    \n    Args:\n        model: Trained model to fine-tune\n        base_model_layers: Number of layers to unfreeze from the end\n    \n    Returns:\n        Model ready for fine-tuning\n    \"\"\"\n    # Find the MobileNetV2 base model\n    base_model = None\n    for layer in model.layers:\n        if 'mobilenet' in layer.name.lower():\n            base_model = layer\n            break\n    \n    if base_model is None:\n        print(\"Warning: Could not find MobileNetV2 base model. Skipping fine-tuning.\")\n        return model\n    \n    # Unfreeze top layers\n    base_model.trainable = True\n    for layer in base_model.layers[:-base_model_layers]:\n        layer.trainable = False\n    \n    # Recompile with lower learning rate\n    model.compile(\n        optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    \n    return model\n","size_bytes":4909},"train_indian_currency_model.py":{"content":"\"\"\"\nTraining Script for Indian Currency Counterfeit Detection\nTrains model on 50, 200, and 500 Rupee notes (genuine vs fake)\n\"\"\"\nimport os\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\n\ndef create_model(input_shape=(224, 224, 3), num_classes=2):\n    \"\"\"\n    Create MobileNetV2-based model for currency detection\n    \n    Args:\n        input_shape: Input image shape\n        num_classes: Number of classes (2: genuine/fake)\n    \n    Returns:\n        Compiled model\n    \"\"\"\n    print(\"Creating MobileNetV2-based model...\")\n    \n    # Load pre-trained MobileNetV2 (without top layer)\n    base_model = MobileNetV2(\n        input_shape=input_shape,\n        include_top=False,\n        weights='imagenet'\n    )\n    \n    # Freeze base model\n    base_model.trainable = False\n    \n    # Build model\n    inputs = keras.Input(shape=input_shape)\n    \n    # Preprocessing for MobileNetV2\n    x = keras.applications.mobilenet_v2.preprocess_input(inputs)\n    \n    # Base model\n    x = base_model(x, training=False)\n    \n    # Classification head\n    x = layers.GlobalAveragePooling2D()(x)\n    x = layers.Dropout(0.5)(x)\n    x = layers.Dense(256, activation='relu')(x)\n    x = layers.Dropout(0.3)(x)\n    x = layers.Dense(128, activation='relu')(x)\n    outputs = layers.Dense(num_classes, activation='softmax')(x)\n    \n    model = keras.Model(inputs, outputs)\n    \n    # Compile\n    model.compile(\n        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    \n    print(\"✓ Model created successfully\")\n    return model\n\ndef fine_tune_model(model, num_layers_to_unfreeze=20):\n    \"\"\"\n    Fine-tune the model by unfreezing some layers\n    \n    Args:\n        model: Trained model\n        num_layers_to_unfreeze: Number of layers to unfreeze from the end\n    \n    Returns:\n        Model ready for fine-tuning\n    \"\"\"\n    print(f\"\\nFine-tuning: Unfreezing last {num_layers_to_unfreeze} layers...\")\n    \n    # Find the MobileNetV2 base model by searching for it\n    base_model = None\n    for layer in model.layers:\n        if 'mobilenet' in layer.name.lower():\n            base_model = layer\n            break\n    \n    if base_model is None:\n        print(\"Warning: Could not find MobileNetV2 base model. Skipping fine-tuning.\")\n        return model\n    \n    # Unfreeze the last layers\n    base_model.trainable = True\n    for layer in base_model.layers[:-num_layers_to_unfreeze]:\n        layer.trainable = False\n    \n    # Recompile with lower learning rate\n    model.compile(\n        optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    \n    print(\"✓ Model prepared for fine-tuning\")\n    return model\n\ndef create_data_generators(train_dir, val_dir, batch_size=16, target_size=(224, 224)):\n    \"\"\"\n    Create data generators with augmentation\n    \n    Args:\n        train_dir: Training data directory\n        val_dir: Validation data directory\n        batch_size: Batch size\n        target_size: Target image size\n    \n    Returns:\n        Training and validation generators\n    \"\"\"\n    print(\"Creating data generators with augmentation...\")\n    \n    # Training data augmentation\n    train_datagen = ImageDataGenerator(\n        rotation_range=10,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        shear_range=0.1,\n        zoom_range=0.1,\n        horizontal_flip=True,\n        fill_mode='nearest'\n    )\n    \n    # Validation data (no augmentation)\n    val_datagen = ImageDataGenerator()\n    \n    # Create generators\n    train_generator = train_datagen.flow_from_directory(\n        train_dir,\n        target_size=target_size,\n        batch_size=batch_size,\n        class_mode='categorical',\n        shuffle=True\n    )\n    \n    val_generator = val_datagen.flow_from_directory(\n        val_dir,\n        target_size=target_size,\n        batch_size=batch_size,\n        class_mode='categorical',\n        shuffle=False\n    )\n    \n    print(f\"✓ Data generators created\")\n    print(f\"  Classes: {train_generator.class_indices}\")\n    return train_generator, val_generator\n\ndef plot_training_history(history, history_fine=None, save_path='model/training_history.png'):\n    \"\"\"Plot and save training history\"\"\"\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n    \n    # Plot accuracy\n    ax1.plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n    ax1.plot(history.history['val_accuracy'], label='Val Accuracy', linewidth=2)\n    \n    if history_fine:\n        offset = len(history.history['accuracy'])\n        ax1.plot(range(offset, offset + len(history_fine.history['accuracy'])), \n                 history_fine.history['accuracy'], label='Train Acc (Fine-tune)', linewidth=2)\n        ax1.plot(range(offset, offset + len(history_fine.history['val_accuracy'])), \n                 history_fine.history['val_accuracy'], label='Val Acc (Fine-tune)', linewidth=2)\n    \n    ax1.set_xlabel('Epoch', fontsize=12)\n    ax1.set_ylabel('Accuracy', fontsize=12)\n    ax1.set_title('Model Accuracy', fontsize=14, fontweight='bold')\n    ax1.legend(fontsize=10)\n    ax1.grid(True, alpha=0.3)\n    \n    # Plot loss\n    ax2.plot(history.history['loss'], label='Train Loss', linewidth=2)\n    ax2.plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n    \n    if history_fine:\n        offset = len(history.history['loss'])\n        ax2.plot(range(offset, offset + len(history_fine.history['loss'])), \n                 history_fine.history['loss'], label='Train Loss (Fine-tune)', linewidth=2)\n        ax2.plot(range(offset, offset + len(history_fine.history['val_loss'])), \n                 history_fine.history['val_loss'], label='Val Loss (Fine-tune)', linewidth=2)\n    \n    ax2.set_xlabel('Epoch', fontsize=12)\n    ax2.set_ylabel('Loss', fontsize=12)\n    ax2.set_title('Model Loss', fontsize=14, fontweight='bold')\n    ax2.legend(fontsize=10)\n    ax2.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n    print(f\"\\n✓ Training history plot saved to {save_path}\")\n\ndef train_model(train_dir='indian_currency_dataset/train', \n                val_dir='indian_currency_dataset/val',\n                epochs=15,\n                fine_tune_epochs=10,\n                batch_size=16):\n    \"\"\"\n    Train the Indian currency detection model\n    \n    Args:\n        train_dir: Training directory\n        val_dir: Validation directory\n        epochs: Number of initial training epochs\n        fine_tune_epochs: Number of fine-tuning epochs\n        batch_size: Batch size\n    \n    Returns:\n        Trained model and history\n    \"\"\"\n    print(\"=\"*70)\n    print(\"TRAINING INDIAN CURRENCY COUNTERFEIT DETECTION MODEL\")\n    print(\"=\"*70)\n    print(f\"Train directory: {train_dir}\")\n    print(f\"Validation directory: {val_dir}\")\n    print(f\"Initial epochs: {epochs}\")\n    print(f\"Fine-tune epochs: {fine_tune_epochs}\")\n    print(f\"Batch size: {batch_size}\")\n    print(\"=\"*70)\n    \n    # Create model\n    model = create_model()\n    print(f\"\\nModel architecture:\")\n    model.summary()\n    \n    # Create data generators\n    train_generator, val_generator = create_data_generators(\n        train_dir, val_dir, batch_size\n    )\n    \n    print(f\"\\nDataset:\")\n    print(f\"  Training samples: {train_generator.samples}\")\n    print(f\"  Validation samples: {val_generator.samples}\")\n    print(f\"  Classes: {train_generator.class_indices}\")\n    \n    # Create model directory\n    os.makedirs('model', exist_ok=True)\n    \n    # Callbacks\n    callbacks = [\n        keras.callbacks.ModelCheckpoint(\n            'model/indian_currency_detector_best.h5',\n            monitor='val_accuracy',\n            save_best_only=True,\n            verbose=1\n        ),\n        keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=5,\n            restore_best_weights=True,\n            verbose=1\n        ),\n        keras.callbacks.ReduceLROnPlateau(\n            monitor='val_loss',\n            factor=0.5,\n            patience=3,\n            min_lr=1e-7,\n            verbose=1\n        )\n    ]\n    \n    # Phase 1: Initial training\n    print(\"\\n\" + \"=\"*70)\n    print(\"PHASE 1: Initial Training (Frozen Base Model)\")\n    print(\"=\"*70)\n    \n    history = model.fit(\n        train_generator,\n        epochs=epochs,\n        validation_data=val_generator,\n        callbacks=callbacks,\n        verbose=1\n    )\n    \n    # Phase 2: Fine-tuning\n    print(\"\\n\" + \"=\"*70)\n    print(\"PHASE 2: Fine-Tuning (Unfreezing Last Layers)\")\n    print(\"=\"*70)\n    \n    model = fine_tune_model(model)\n    \n    history_fine = model.fit(\n        train_generator,\n        epochs=fine_tune_epochs,\n        validation_data=val_generator,\n        callbacks=callbacks,\n        verbose=1\n    )\n    \n    # Save final model\n    model.save('model/indian_currency_detector.h5')\n    print(\"\\n✓ Final model saved to model/indian_currency_detector.h5\")\n    \n    # Also save to CounterfeitGuard directory\n    model.save('CounterfeitGuard/model/currency_detector.h5')\n    print(\"✓ Model copied to CounterfeitGuard/model/currency_detector.h5\")\n    \n    # Evaluate\n    print(\"\\n\" + \"=\"*70)\n    print(\"FINAL EVALUATION\")\n    print(\"=\"*70)\n    \n    val_loss, val_accuracy = model.evaluate(val_generator, verbose=0)\n    print(f\"Validation Accuracy: {val_accuracy*100:.2f}%\")\n    print(f\"Validation Loss: {val_loss:.4f}\")\n    \n    # Plot training history\n    plot_training_history(history, history_fine)\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"TRAINING COMPLETE!\")\n    print(\"=\"*70)\n    print(\"Model saved to:\")\n    print(\"  • model/indian_currency_detector.h5\")\n    print(\"  • CounterfeitGuard/model/currency_detector.h5\")\n    print(\"Training history plot:\")\n    print(\"  • model/training_history.png\")\n    print(\"=\"*70)\n    \n    return model, history, history_fine\n\nif __name__ == '__main__':\n    # Check if dataset exists\n    train_dir = 'indian_currency_dataset/train'\n    val_dir = 'indian_currency_dataset/val'\n    \n    if not os.path.exists(train_dir) or not os.path.exists(val_dir):\n        print(\"=\"*70)\n        print(\"ERROR: Dataset not found!\")\n        print(\"=\"*70)\n        print(f\"Expected directories:\")\n        print(f\"  {train_dir}\")\n        print(f\"  {val_dir}\")\n        print(\"\\nPlease run first:\")\n        print(\"  python create_indian_currency_dataset.py\")\n        print(\"=\"*70)\n    else:\n        # Train the model\n        model, history, history_fine = train_model(\n            train_dir=train_dir,\n            val_dir=val_dir,\n            epochs=15,\n            fine_tune_epochs=10,\n            batch_size=16\n        )\n","size_bytes":10835},"CounterfeitGuard/README.md":{"content":"# Fake Currency Detector\n\nAI-powered web application that detects whether a currency note is genuine or fake using deep learning.\n\n## Features\n\n- **CNN-based Detection**: Uses MobileNetV2 transfer learning for binary classification\n- **High Accuracy**: Designed to achieve >96% accuracy with proper training data\n- **Grad-CAM Visualization**: Highlights suspicious regions on the currency note\n- **Confidence Scores**: Shows probability percentages for genuine vs fake\n- **Simple Web Interface**: Easy-to-use upload and analyze interface\n- **Real-time Analysis**: Quick predictions with visual feedback\n\n## Tech Stack\n\n- **Backend**: Flask 3.0\n- **ML Framework**: TensorFlow 2.15 with Keras\n- **Model**: MobileNetV2 (transfer learning)\n- **Image Processing**: OpenCV, Pillow\n- **Visualization**: Matplotlib, Grad-CAM\n- **Frontend**: HTML, CSS, JavaScript\n\n## Project Structure\n\n```\n.\n├── app.py                  # Flask API with /predict endpoint\n├── model.py                # CNN model architecture and utilities\n├── train_model.py          # Training script for the model\n├── requirements.txt        # Python dependencies\n├── templates/\n│   └── index.html         # Web interface\n├── model/\n│   └── currency_detector.h5  # Trained model (created after training)\n└── uploads/               # Temporary storage for uploaded images\n```\n\n## Installation\n\nThe required packages are already installed in this Replit environment:\n\n- tensorflow==2.15.0\n- flask==3.0.0\n- opencv-python==4.8.1.78\n- numpy==1.24.3\n- pillow==10.1.0\n- matplotlib==3.8.2\n- werkzeug==3.0.1\n\n## Usage\n\n### Running the Application\n\nThe Flask app is already configured to run automatically. Simply:\n\n1. Click the \"Run\" button or access the webview\n2. Upload a currency note image (PNG, JPG, or JPEG)\n3. Click \"Analyze Currency\"\n4. View results with confidence scores and Grad-CAM visualization\n\n### API Endpoints\n\n#### `GET /`\nReturns the main web interface\n\n#### `POST /predict`\nAccepts image file and returns prediction results\n\n**Request:**\n- Method: POST\n- Content-Type: multipart/form-data\n- Body: `file` (image file)\n\n**Response:**\n```json\n{\n  \"prediction\": \"Genuine\" or \"Fake\",\n  \"confidence\": 95.34,\n  \"is_genuine\": true,\n  \"probabilities\": {\n    \"fake\": 4.66,\n    \"genuine\": 95.34\n  },\n  \"gradcam_image\": \"/gradcam/gradcam_filename.png\"\n}\n```\n\n#### `GET /gradcam/<filename>`\nReturns the Grad-CAM visualization image\n\n## Training Your Own Model\n\nThe current model is a demo with random weights. To train with real data:\n\n1. **Prepare Dataset**: Organize images into this structure:\n   ```\n   dataset/\n   ├── train/\n   │   ├── fake/       # Fake currency images\n   │   └── genuine/    # Genuine currency images\n   └── val/\n       ├── fake/       # Validation fake images\n       └── genuine/    # Validation genuine images\n   ```\n\n2. **Run Training**:\n   ```bash\n   python train_model.py\n   ```\n\n3. **Training Features**:\n   - Transfer learning with MobileNetV2\n   - Data augmentation (rotation, zoom, brightness, flip)\n   - Early stopping to prevent overfitting\n   - Learning rate reduction on plateau\n   - Model checkpointing (saves best model)\n   - Fine-tuning of top layers\n\n4. **Training Outputs**:\n   - `model/currency_detector.h5` - Final trained model\n   - `model/currency_detector_best.h5` - Best model during training\n   - `model/training_history.png` - Training metrics visualization\n\n## Model Architecture\n\n- **Base Model**: MobileNetV2 (pretrained on ImageNet)\n- **Custom Layers**:\n  - Global Average Pooling\n  - Dense(256) + ReLU + Dropout(0.5)\n  - Dense(128) + ReLU + Dropout(0.3)\n  - Dense(2) + Softmax (output)\n\n- **Input Shape**: 224x224x3 RGB images\n- **Output**: 2 classes (Fake, Genuine)\n\n## Data Augmentation\n\nThe training pipeline includes:\n- Rotation (±20 degrees)\n- Width/Height shift (20%)\n- Shear transformation (20%)\n- Zoom (20%)\n- Horizontal flip\n- Brightness adjustment (80-120%)\n\n## Grad-CAM Visualization\n\nGradient-weighted Class Activation Mapping (Grad-CAM) shows:\n- Which parts of the currency note the model focused on\n- Red/yellow regions indicate high importance\n- Blue regions indicate low importance\n- Helps identify suspicious features on fake notes\n\n## Important Notes\n\n1. **Demo Model**: The current model has random weights and won't give accurate predictions\n2. **Training Data**: You need real currency images (genuine and fake) to train properly\n3. **Accuracy Target**: With proper dataset, the model should achieve >96% accuracy\n4. **Legal Disclaimer**: This is for educational purposes only. Consult local laws regarding currency image handling\n\n## How It Works\n\n1. **Upload**: User uploads currency note image\n2. **Preprocessing**: Image is resized to 224x224 and preprocessed for MobileNet\n3. **Prediction**: Model classifies as genuine or fake with confidence score\n4. **Grad-CAM**: Generates heatmap showing important regions\n5. **Display**: Results shown with overlaid visualization\n\n## Performance Tips\n\n- Use clear, well-lit images\n- Ensure the entire note is visible\n- Avoid blurry or distorted images\n- Higher resolution images work better\n\n## Future Enhancements\n\n- Denomination detection\n- Currency type identification\n- Batch processing\n- REST API documentation\n- Model performance metrics dashboard\n- Database logging of predictions\n\n## License\n\nEducational project - use responsibly and in accordance with local laws.\n","size_bytes":5452},"replit.md":{"content":"# Fake Currency Detector\n\n## Overview\n\nAn AI-powered web application that detects whether a currency note is genuine or fake using deep learning. The system uses transfer learning with MobileNetV2 architecture and provides visual explanations through Grad-CAM (Gradient-weighted Class Activation Mapping) heatmaps that highlight suspicious regions on currency notes.\n\n## User Preferences\n\nPreferred communication style: Simple, everyday language.\n\n## Recent Changes\n\n### November 2, 2025\n- **Kaggle Dataset Integration & Model Training**: Successfully integrated Kaggle API for dataset management\n  - Installed Kaggle package and configured API authentication using environment secrets\n  - Downloaded and organized Indian currency counterfeit detection dataset\n  - Final dataset: 72 training images (32 fake + 40 genuine), 18 validation images (8 fake + 10 genuine)\n  \n- **Two-Phase Transfer Learning Training**:\n  - **Phase 1 (Initial Training)**: Frozen MobileNetV2 base model, 15 epochs\n    - Training accuracy: 100%\n    - Validation accuracy: 94.44%\n    - Early stopping triggered after 12 epochs\n  - **Phase 2 (Fine-Tuning)**: Unfroze last 20 layers, 10 epochs, lower learning rate (0.0001)\n    - Training accuracy: 100%\n    - **Final validation accuracy: 100%**\n    - Improvement: +5.56%\n  - Model saved to: `CounterfeitGuard/model/currency_detector.h5` (14MB)\n  \n- **Training Infrastructure**:\n  - Scripts: `download_kaggle_dataset.py`, `train_indian_currency_model.py`, `complete_training.py`\n  - Callbacks: ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n  - Data augmentation: rotation, shift, shear, zoom, horizontal flip\n  - Fixed fine-tuning bug by properly identifying MobileNetV2 layer\n  \n- **Model Performance Notes** (from architect review):\n  - Small dataset (90 total images) means 100% accuracy should be interpreted cautiously\n  - Likely overfitting on validation set due to limited samples\n  - Recommendations for future: expand dataset with real captures, implement cross-validation, enhance augmentation\n  \n- **Previous Training**: Initial model with stock images + synthetic fakes\n  - Evaluation script: `evaluate_model.py` with confusion matrix visualization\n\n### November 1, 2025\n- **Upload Storage**: Modified upload directory from project folder to temporary directory (`/tmp/currency_uploads`)\n  - Prevents project folder pollution\n  - Uses secure filename handling to prevent directory traversal attacks\n\n## System Architecture\n\n### Frontend Architecture\n- **Technology**: HTML templates with Jinja2 templating engine\n- **Interface Components**: \n  - Main detection page with drag-and-drop file upload\n  - Testing dashboard for model debugging and batch testing\n  - Authentication pages (login/register)\n  - Base template system for consistent navigation and layout\n- **Styling**: Custom CSS with modern design patterns (gradients, shadows, responsive cards)\n- **Client-side Logic**: JavaScript for file handling, preview generation, and asynchronous API communication\n\n### Backend Architecture\n- **Framework**: Flask 3.0 web application\n- **Design Pattern**: MVC-style separation with templates, routes, and model logic\n- **API Endpoints**:\n  - `/predict` - Image classification endpoint\n  - Authentication routes (login, register, logout)\n  - Testing dashboard route\n- **File Handling**: Werkzeug secure filename processing with 16MB upload limit\n- **Session Management**: Flask-Login for user authentication with session-based authentication\n\n### Machine Learning Architecture\n- **Base Model**: MobileNetV2 pre-trained on ImageNet (transfer learning approach)\n- **Model Structure**:\n  - Frozen MobileNetV2 base for feature extraction\n  - Global average pooling layer\n  - Custom classification head with dense layers (256 → 128 neurons)\n  - Dropout regularization (0.5 and 0.3) to prevent overfitting\n  - Softmax output for binary classification (genuine/fake)\n- **Input**: 224x224x3 RGB images\n- **Training Strategy**: Two-phase training (frozen base, then fine-tuning)\n- **Visualization**: Grad-CAM implementation for explainable AI - highlights image regions influencing predictions\n\n### Data Storage\n- **Database**: SQLite with SQLAlchemy ORM\n- **Schema**: User model with email and password hash fields\n- **Security**: Werkzeug password hashing (generate_password_hash/check_password_hash)\n- **File Storage**: Local filesystem for uploaded images and trained models\n- **Model Persistence**: Keras H5 format for saved models\n\n### Authentication & Authorization\n- **Library**: Flask-Login for session management\n- **User Model**: SQLAlchemy-based User class implementing UserMixin\n- **Password Security**: Hashed passwords using Werkzeug security utilities\n- **Protected Routes**: `@login_required` decorator for restricted endpoints\n- **Session**: Server-side session with configurable secret key\n\n## External Dependencies\n\n### Core ML Framework\n- **TensorFlow 2.15**: Deep learning framework for model training and inference\n- **Keras**: High-level neural networks API (part of TensorFlow)\n- **MobileNetV2 Weights**: Pre-trained ImageNet weights downloaded from Keras applications\n\n### Image Processing\n- **OpenCV 4.8.1**: Computer vision library for image preprocessing\n- **Pillow 10.1.0**: Python Imaging Library for image I/O and manipulation\n- **NumPy 1.24.3**: Numerical computing for array operations\n\n### Web Framework\n- **Flask 3.0.0**: Lightweight WSGI web application framework\n- **Flask-SQLAlchemy**: ORM integration for database operations\n- **Flask-Login**: User session management\n- **Werkzeug 3.0.1**: WSGI utilities and security helpers\n\n### Visualization\n- **Matplotlib 3.8.2**: Plotting library for Grad-CAM heatmap generation\n\n### Training Infrastructure\n- **Data Augmentation**: ImageDataGenerator for training data preprocessing and augmentation (rotation, zoom, shift, flip)\n- **Synthetic Data Generation**: Custom script for creating demonstration currency images when real datasets unavailable\n- **Callbacks**: ModelCheckpoint for saving best models, EarlyStopping for training optimization\n\n### Deployment Environment\n- **Platform**: Replit with Python 3.11 runtime\n- **Port Configuration**: Flask runs on port 5000 with webview\n- **Scaling**: Autoscale deployment mode\n- **Environment Variables**: SECRET_KEY for session security","size_bytes":6297},"CounterfeitGuard/create_user.py":{"content":"#!/usr/bin/env python\n\"\"\"Script to create a user account\"\"\"\nfrom app import app, db, User\n\ndef create_user(username, password):\n    with app.app_context():\n        # Check if user already exists\n        existing_user = User.query.filter_by(username=username).first()\n        if existing_user:\n            print(f\"User '{username}' already exists!\")\n            return False\n        \n        # Create new user\n        user = User(username=username)\n        user.set_password(password)\n        db.session.add(user)\n        db.session.commit()\n        print(f\"User '{username}' created successfully!\")\n        return True\n\nif __name__ == '__main__':\n    # Create a demo user\n    username = \"admin\"\n    password = \"admin123\"\n    \n    create_user(username, password)\n    print(f\"\\nLogin credentials:\")\n    print(f\"Username: {username}\")\n    print(f\"Password: {password}\")\n","size_bytes":867},"prepare_indian_currency_dataset.py":{"content":"\"\"\"\nDownload and prepare Indian Currency dataset for training\nFocuses on 50, 200, and 500 rupee notes (genuine and fake)\n\"\"\"\nimport os\nimport requests\nfrom pathlib import Path\nimport zipfile\nimport shutil\n\ndef download_file(url, destination):\n    \"\"\"Download file with progress indication\"\"\"\n    print(f\"Downloading from {url}...\")\n    try:\n        response = requests.get(url, stream=True, timeout=30)\n        response.raise_for_status()\n        \n        total_size = int(response.headers.get('content-length', 0))\n        \n        with open(destination, 'wb') as f:\n            if total_size == 0:\n                f.write(response.content)\n            else:\n                downloaded = 0\n                for chunk in response.iter_content(chunk_size=8192):\n                    downloaded += len(chunk)\n                    f.write(chunk)\n                    done = int(50 * downloaded / total_size)\n                    print(f\"\\r[{'=' * done}{' ' * (50-done)}] {downloaded}/{total_size} bytes\", end='')\n        print(\"\\nDownload complete!\")\n        return True\n    except Exception as e:\n        print(f\"\\nError downloading: {e}\")\n        return False\n\ndef setup_dataset_structure():\n    \"\"\"Create directory structure for training\"\"\"\n    print(\"\\nSetting up dataset directory structure...\")\n    \n    base_dir = Path('indian_currency_dataset')\n    \n    # Create directories for each denomination\n    for split in ['train', 'val']:\n        for denomination in ['50', '200', '500']:\n            for category in ['genuine', 'fake']:\n                dir_path = base_dir / split / denomination / category\n                dir_path.mkdir(parents=True, exist_ok=True)\n    \n    print(\"Directory structure created:\")\n    print(\"  indian_currency_dataset/\")\n    print(\"    train/\")\n    print(\"      50/ (genuine/, fake/)\")\n    print(\"      200/ (genuine/, fake/)\")\n    print(\"      500/ (genuine/, fake/)\")\n    print(\"    val/\")\n    print(\"      50/ (genuine/, fake/)\")\n    print(\"      200/ (genuine/, fake/)\")\n    print(\"      500/ (genuine/, fake/)\")\n    \n    return base_dir\n\ndef download_mendeley_dataset():\n    \"\"\"\n    Download Mendeley Indian Currency Dataset\n    Note: This is a public dataset for research purposes\n    \"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(\"MENDELEY INDIAN CURRENCY DATASET\")\n    print(\"=\"*70)\n    print(\"Dataset: Indian Currency Dataset\")\n    print(\"Source: Mendeley Data\")\n    print(\"URL: https://data.mendeley.com/datasets/8ckhkssyn3/1\")\n    print(\"License: CC BY 4.0\")\n    print(\"\\nThis dataset contains:\")\n    print(\"  - 50 Rs: 272 images\")\n    print(\"  - 200 Rs: 205 images\")\n    print(\"  - 500 Rs: 223 images\")\n    print(\"  - Other denominations: 10, 20, 100, 2000\")\n    print(\"\\nTotal: 1,786 genuine currency note images\")\n    print(\"=\"*70)\n    \n    # Direct download URL for Mendeley dataset (if available)\n    # Note: Mendeley datasets often require manual download\n    dataset_url = \"https://data.mendeley.com/public-files/datasets/8ckhkssyn3/files/e5c0a17a-4c6f-4f2b-8c6e-3e0d8c6f5f5e/file_downloaded\"\n    \n    print(\"\\n⚠️  MANUAL DOWNLOAD REQUIRED\")\n    print(\"Please follow these steps:\")\n    print(\"1. Visit: https://data.mendeley.com/datasets/8ckhkssyn3/1\")\n    print(\"2. Click 'Download' to get the dataset\")\n    print(\"3. Extract the zip file to 'indian_currency_dataset/downloaded/'\")\n    print(\"4. Run this script again to organize the files\")\n    \n    return False\n\ndef create_fake_samples_using_augmentation():\n    \"\"\"\n    Create synthetic fake currency samples using data augmentation\n    This simulates characteristics of counterfeit notes\n    \"\"\"\n    from PIL import Image, ImageFilter, ImageEnhance\n    import random\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"CREATING SYNTHETIC FAKE CURRENCY SAMPLES\")\n    print(\"=\"*70)\n    print(\"Using data augmentation to simulate counterfeit characteristics:\")\n    print(\"  - Color distortion (fake notes have off colors)\")\n    print(\"  - Blur (lower print quality)\")\n    print(\"  - Reduced sharpness (poor printing)\")\n    print(\"  - Brightness/contrast variations\")\n    print(\"=\"*70)\n    \n    base_dir = Path('indian_currency_dataset')\n    \n    # For each denomination, create fake versions from genuine\n    for denomination in ['50', '200', '500']:\n        genuine_dir = base_dir / 'train' / denomination / 'genuine'\n        fake_dir = base_dir / 'train' / denomination / 'fake'\n        \n        if not genuine_dir.exists():\n            print(f\"\\nNo genuine images found for {denomination} Rs. Skipping...\")\n            continue\n        \n        genuine_images = list(genuine_dir.glob('*.jpg')) + list(genuine_dir.glob('*.png'))\n        \n        if len(genuine_images) == 0:\n            print(f\"\\nNo images found in {genuine_dir}. Skipping...\")\n            continue\n        \n        print(f\"\\nCreating fake samples for {denomination} Rs...\")\n        print(f\"  Source: {len(genuine_images)} genuine images\")\n        \n        # Create fake versions with augmentation\n        for idx, img_path in enumerate(genuine_images[:min(len(genuine_images), 100)]):\n            try:\n                img = Image.open(img_path)\n                \n                # Apply multiple augmentations to simulate fake characteristics\n                # 1. Color shift (counterfeit notes often have off colors)\n                enhancer = ImageEnhance.Color(img)\n                img = enhancer.enhance(random.uniform(0.7, 1.3))\n                \n                # 2. Add blur (lower quality printing)\n                img = img.filter(ImageFilter.GaussianBlur(radius=random.uniform(0.5, 1.5)))\n                \n                # 3. Reduce sharpness\n                enhancer = ImageEnhance.Sharpness(img)\n                img = enhancer.enhance(random.uniform(0.5, 0.8))\n                \n                # 4. Adjust brightness (inconsistent printing)\n                enhancer = ImageEnhance.Brightness(img)\n                img = enhancer.enhance(random.uniform(0.8, 1.2))\n                \n                # 5. Adjust contrast\n                enhancer = ImageEnhance.Contrast(img)\n                img = enhancer.enhance(random.uniform(0.7, 1.3))\n                \n                # Save fake version\n                fake_filename = f'fake_{denomination}_{idx:04d}.jpg'\n                img.save(fake_dir / fake_filename, quality=85)  # Lower quality\n                \n                if (idx + 1) % 20 == 0:\n                    print(f\"    Generated {idx + 1} fake samples...\")\n            \n            except Exception as e:\n                print(f\"    Error processing {img_path.name}: {e}\")\n        \n        print(f\"  Completed: Created synthetic fake samples for {denomination} Rs\")\n    \n    return True\n\ndef main():\n    \"\"\"Main execution\"\"\"\n    print(\"=\"*70)\n    print(\"INDIAN CURRENCY DATASET PREPARATION\")\n    print(\"For Counterfeit Detection (50, 200, 500 Rupees)\")\n    print(\"=\"*70)\n    \n    # Setup directory structure\n    base_dir = setup_dataset_structure()\n    \n    # Download genuine currency dataset\n    print(\"\\n\" + \"=\"*70)\n    print(\"STEP 1: Download Genuine Currency Dataset\")\n    print(\"=\"*70)\n    download_mendeley_dataset()\n    \n    # Check if user has manually downloaded files\n    downloaded_dir = Path('indian_currency_dataset/downloaded')\n    if downloaded_dir.exists() and any(downloaded_dir.iterdir()):\n        print(\"\\n✓ Downloaded files detected!\")\n        print(\"Organizing dataset...\")\n        # Here you would add code to organize the downloaded files\n        # into the proper train/val structure\n    else:\n        print(\"\\n⚠️  No downloaded files found.\")\n        print(\"After downloading the Mendeley dataset:\")\n        print(\"  1. Extract files to: indian_currency_dataset/downloaded/\")\n        print(\"  2. Run this script again\")\n        print(\"\\nFor now, I'll create a demonstration dataset using stock images...\")\n        \n        # Use stock images as placeholders\n        use_stock_images_as_placeholders(base_dir)\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"DATASET PREPARATION INSTRUCTIONS\")\n    print(\"=\"*70)\n    print(\"To complete the dataset setup:\")\n    print(\"\\n1. Download the Mendeley dataset:\")\n    print(\"   https://data.mendeley.com/datasets/8ckhkssyn3/1\")\n    print(\"\\n2. Extract genuine currency images for 50, 200, 500 Rs to:\")\n    print(\"   indian_currency_dataset/train/{denomination}/genuine/\")\n    print(\"\\n3. Run: python prepare_indian_currency_dataset.py\")\n    print(\"   This will create synthetic fake samples using augmentation\")\n    print(\"\\n4. Then train: python CounterfeitGuard/train_model.py\")\n    print(\"=\"*70)\n\ndef use_stock_images_as_placeholders(base_dir):\n    \"\"\"Use stock images of Indian currency as placeholders\"\"\"\n    print(\"\\nUsing stock images for demonstration...\")\n    print(\"Note: For production use, please use actual currency datasets\")\n    \n    # This would use the stock_image_tool to download sample images\n    # For now, we'll note that manual dataset is needed\n    \n    return True\n\nif __name__ == '__main__':\n    main()\n","size_bytes":8964},"add_user.py":{"content":"#!/usr/bin/env python\n\"\"\"Script to create a user account for the Currency Detector app\"\"\"\nimport sys\nsys.path.insert(0, '.')\n\nfrom flask import Flask\nfrom flask_sqlalchemy import SQLAlchemy\nfrom werkzeug.security import generate_password_hash\nimport os\n\n# Create minimal Flask app just for database operations\napp = Flask(__name__)\napp.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///CounterfeitGuard/instance/currency_detector.db'\napp.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False\n\ndb = SQLAlchemy(app)\n\nclass User(db.Model):\n    id = db.Column(db.Integer, primary_key=True)\n    username = db.Column(db.String(80), unique=True, nullable=False)\n    password_hash = db.Column(db.String(200), nullable=False)\n\ndef create_user(username, password):\n    with app.app_context():\n        # Check if user already exists\n        existing_user = User.query.filter_by(username=username).first()\n        if existing_user:\n            print(f\"User '{username}' already exists!\")\n            return False\n        \n        # Create new user\n        user = User(username=username)\n        user.password_hash = generate_password_hash(password)\n        db.session.add(user)\n        db.session.commit()\n        print(f\"✓ User '{username}' created successfully!\")\n        return True\n\nif __name__ == '__main__':\n    # Create admin user\n    username = \"admin\"\n    password = \"admin123\"\n    \n    create_user(username, password)\n    print(f\"\\nYour login credentials:\")\n    print(f\"  Username: {username}\")\n    print(f\"  Password: {password}\")\n    print(\"\\nYou can now login to the Currency Detector app!\")\n","size_bytes":1587},"CounterfeitGuard/replit.md":{"content":"# Fake Currency Detector Web App\n\n## Overview\nA CNN-based web application that detects whether a currency note is genuine or fake using deep learning. The app uses transfer learning with MobileNet architecture and provides Grad-CAM visualizations to highlight suspicious regions on the currency notes.\n\n## Project Architecture\n- **Backend**: Flask API with TensorFlow/Keras for ML inference\n- **Model**: MobileNet-based CNN with custom classification layers\n- **Visualization**: Grad-CAM heatmap overlays on input images\n- **Frontend**: Simple HTML/CSS interface for image uploads\n\n## Recent Changes\n- **Testing Dashboard Added** (Oct 31, 2025)\n  - Created comprehensive testing page at `/testing`\n  - Model information display (status, layers, input/output shapes)\n  - Batch image testing capability\n  - Model architecture inspector showing all layers\n  - Quick test results with confidence scores\n  - Link from main app to testing dashboard\n- **Grad-CAM Layer Fix** (Oct 31, 2025)\n  - Fixed Grad-CAM function to auto-detect the correct convolutional layer\n  - Updated make_gradcam_heatmap to access layers within MobileNetV2 base model\n  - App now handles both trained and demo models correctly\n- **Replit Environment Setup** (Oct 31, 2025)\n  - Imported from GitHub and configured for Replit\n  - Python 3.11 module installed\n  - All dependencies installed (TensorFlow 2.15, Flask 3.0, OpenCV, etc.)\n  - Workflow configured to run Flask app on port 5000 with webview\n  - Deployment configuration set up (autoscale mode)\n  - Created model and uploads directories\n  - MobileNetV2 pretrained weights downloaded successfully\n  - Demo model created (no trained model yet - needs dataset)\n  - Web interface verified and working\n  - Root .gitignore added for Python artifacts\n- **Previous Development** (Before import)\n  - Model architecture created with MobileNetV2 transfer learning\n  - Training scripts completed (train_model.py)\n  - Grad-CAM visualization implemented\n  - Web interface designed\n\n## Tech Stack\n- Python 3.11\n- TensorFlow 2.15 (CNN model with MobileNet transfer learning)\n- Flask 3.0 (REST API)\n- OpenCV (image preprocessing)\n- NumPy, Pillow, Matplotlib (data processing and visualization)\n\n## Features\n1. Binary classification: genuine vs fake currency\n2. Transfer learning using MobileNet\n3. Data augmentation for improved accuracy\n4. Grad-CAM visualization for explainability\n5. Confidence score display\n6. Simple web interface for image upload\n\n## Target\n- Model accuracy: >96%\n","size_bytes":2495},"evaluate_model.py":{"content":"\"\"\"\nEvaluate the trained Indian Currency Counterfeit Detection Model\n\"\"\"\nimport os\nimport numpy as np\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\n\ndef load_trained_model(model_path='model/indian_currency_detector_best.h5'):\n    \"\"\"Load the trained model\"\"\"\n    print(f\"Loading model from {model_path}...\")\n    model = keras.models.load_model(model_path)\n    print(\"✓ Model loaded successfully\")\n    return model\n\ndef evaluate_on_validation_set(model, val_dir='indian_currency_dataset/val'):\n    \"\"\"Evaluate model on validation set\"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(\"EVALUATING ON VALIDATION SET\")\n    print(\"=\"*70)\n    \n    # Create data generator (no augmentation for validation)\n    val_datagen = ImageDataGenerator()\n    val_generator = val_datagen.flow_from_directory(\n        val_dir,\n        target_size=(224, 224),\n        batch_size=1,\n        class_mode='categorical',\n        shuffle=False\n    )\n    \n    print(f\"Validation samples: {val_generator.samples}\")\n    print(f\"Classes: {val_generator.class_indices}\")\n    \n    # Evaluate\n    print(\"\\nEvaluating...\")\n    loss, accuracy = model.evaluate(val_generator, verbose=0)\n    \n    print(f\"\\n{'='*70}\")\n    print(f\"VALIDATION RESULTS\")\n    print(f\"{'='*70}\")\n    print(f\"Accuracy: {accuracy*100:.2f}%\")\n    print(f\"Loss: {loss:.4f}\")\n    \n    # Get predictions\n    print(\"\\nGenerating predictions...\")\n    predictions = model.predict(val_generator, verbose=0)\n    predicted_classes = np.argmax(predictions, axis=1)\n    true_classes = val_generator.classes\n    class_labels = list(val_generator.class_indices.keys())\n    \n    # Confusion matrix\n    cm = confusion_matrix(true_classes, predicted_classes)\n    \n    print(f\"\\nConfusion Matrix:\")\n    print(f\"{'='*70}\")\n    print(f\"                 Predicted\")\n    print(f\"               Fake  Genuine\")\n    print(f\"Actual  Fake    {cm[0][0]:3d}     {cm[0][1]:3d}\")\n    print(f\"      Genuine  {cm[1][0]:3d}     {cm[1][1]:3d}\")\n    \n    # Classification report\n    print(f\"\\n{'='*70}\")\n    print(\"DETAILED CLASSIFICATION REPORT\")\n    print(f\"{'='*70}\")\n    print(classification_report(true_classes, predicted_classes, \n                                target_names=class_labels, digits=4))\n    \n    # Sample predictions\n    print(f\"\\n{'='*70}\")\n    print(\"SAMPLE PREDICTIONS\")\n    print(f\"{'='*70}\")\n    filenames = val_generator.filenames\n    for i in range(min(12, len(filenames))):\n        true_label = class_labels[true_classes[i]]\n        pred_label = class_labels[predicted_classes[i]]\n        confidence = predictions[i][predicted_classes[i]] * 100\n        status = \"✓\" if true_label == pred_label else \"✗\"\n        print(f\"{status} {filenames[i]:50s} | True: {true_label:8s} | Pred: {pred_label:8s} ({confidence:5.1f}%)\")\n    \n    return accuracy, predictions, true_classes, predicted_classes\n\ndef create_confusion_matrix_plot(true_classes, predicted_classes, class_labels):\n    \"\"\"Create and save confusion matrix plot\"\"\"\n    cm = confusion_matrix(true_classes, predicted_classes)\n    \n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n                xticklabels=class_labels, yticklabels=class_labels,\n                cbar_kws={'label': 'Count'})\n    plt.title('Confusion Matrix - Indian Currency Detection', fontsize=14, fontweight='bold')\n    plt.ylabel('True Label', fontsize=12)\n    plt.xlabel('Predicted Label', fontsize=12)\n    plt.tight_layout()\n    \n    save_path = 'model/confusion_matrix.png'\n    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n    print(f\"\\n✓ Confusion matrix saved to {save_path}\")\n\ndef main():\n    \"\"\"Main evaluation\"\"\"\n    print(\"=\"*70)\n    print(\"INDIAN CURRENCY COUNTERFEIT DETECTION - MODEL EVALUATION\")\n    print(\"=\"*70)\n    \n    # Load model\n    model = load_trained_model()\n    \n    # Evaluate on validation set\n    accuracy, predictions, true_classes, predicted_classes = evaluate_on_validation_set(model)\n    \n    # Create visualizations\n    class_labels = ['fake', 'genuine']\n    create_confusion_matrix_plot(true_classes, predicted_classes, class_labels)\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"EVALUATION COMPLETE!\")\n    print(\"=\"*70)\n    print(f\"Final Validation Accuracy: {accuracy*100:.2f}%\")\n    print(\"\\nOutput files:\")\n    print(\"  • model/confusion_matrix.png\")\n    print(\"=\"*70)\n\nif __name__ == '__main__':\n    main()\n","size_bytes":4538},"CounterfeitGuard/static/css/style.css":{"content":":root {\n    --primary-gradient: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n    --primary-color: #667eea;\n    --primary-dark: #764ba2;\n    --success-color: #4caf50;\n    --danger-color: #f44336;\n    --warning-color: #ff9800;\n    --info-color: #2196f3;\n    --text-dark: #333;\n    --text-medium: #666;\n    --text-light: #999;\n    --bg-light: #f8f9ff;\n    --bg-white: #ffffff;\n    --border-radius: 15px;\n    --border-radius-sm: 10px;\n    --border-radius-lg: 20px;\n    --shadow-sm: 0 2px 10px rgba(0, 0, 0, 0.1);\n    --shadow-md: 0 10px 30px rgba(0, 0, 0, 0.2);\n    --shadow-lg: 0 20px 60px rgba(0, 0, 0, 0.3);\n    --transition: all 0.3s ease;\n}\n\n* {\n    margin: 0;\n    padding: 0;\n    box-sizing: border-box;\n}\n\nbody {\n    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n    background: var(--primary-gradient);\n    min-height: 100vh;\n    color: var(--text-dark);\n}\n\n.navbar {\n    background: var(--bg-white);\n    padding: 1rem 0;\n    box-shadow: var(--shadow-sm);\n    position: sticky;\n    top: 0;\n    z-index: 1000;\n}\n\n.navbar-container {\n    max-width: 1200px;\n    margin: 0 auto;\n    padding: 0 20px;\n    display: flex;\n    justify-content: space-between;\n    align-items: center;\n}\n\n.navbar-brand {\n    font-size: 1.5em;\n    font-weight: 700;\n    color: var(--primary-color);\n    text-decoration: none;\n    display: flex;\n    align-items: center;\n    gap: 10px;\n}\n\n.navbar-menu {\n    display: flex;\n    list-style: none;\n    gap: 30px;\n    align-items: center;\n}\n\n.navbar-menu a {\n    color: var(--text-medium);\n    text-decoration: none;\n    font-weight: 500;\n    padding: 8px 16px;\n    border-radius: 8px;\n    transition: var(--transition);\n}\n\n.navbar-menu a:hover {\n    color: var(--primary-color);\n    background: var(--bg-light);\n}\n\n.navbar-menu a.active {\n    color: var(--primary-color);\n    background: var(--bg-light);\n    font-weight: 600;\n}\n\n.user-menu {\n    display: flex;\n    align-items: center;\n    gap: 15px;\n}\n\n.user-avatar {\n    width: 35px;\n    height: 35px;\n    border-radius: 50%;\n    background: var(--primary-gradient);\n    display: flex;\n    align-items: center;\n    justify-content: center;\n    color: white;\n    font-weight: 600;\n    font-size: 0.9em;\n}\n\n.main-content {\n    max-width: 1200px;\n    margin: 0 auto;\n    padding: 30px 20px;\n}\n\n.card {\n    background: var(--bg-white);\n    border-radius: var(--border-radius);\n    padding: 30px;\n    box-shadow: var(--shadow-md);\n    margin-bottom: 20px;\n}\n\n.card-header {\n    margin-bottom: 25px;\n    padding-bottom: 15px;\n    border-bottom: 2px solid var(--bg-light);\n}\n\n.card-title {\n    font-size: 2em;\n    color: var(--text-dark);\n    margin-bottom: 10px;\n}\n\n.card-subtitle {\n    color: var(--text-medium);\n    font-size: 1.1em;\n}\n\n.btn {\n    background: var(--primary-gradient);\n    color: white;\n    border: none;\n    padding: 12px 30px;\n    border-radius: 25px;\n    font-size: 1em;\n    font-weight: 500;\n    cursor: pointer;\n    transition: var(--transition);\n    text-decoration: none;\n    display: inline-block;\n}\n\n.btn:hover {\n    transform: translateY(-2px);\n    box-shadow: 0 10px 20px rgba(102, 126, 234, 0.4);\n}\n\n.btn:disabled {\n    opacity: 0.5;\n    cursor: not-allowed;\n    transform: none;\n}\n\n.btn-secondary {\n    background: linear-gradient(135deg, #6c757d 0%, #495057 100%);\n}\n\n.btn-success {\n    background: linear-gradient(135deg, #4caf50 0%, #388e3c 100%);\n}\n\n.btn-danger {\n    background: linear-gradient(135deg, #f44336 0%, #d32f2f 100%);\n}\n\n.btn-outline {\n    background: transparent;\n    border: 2px solid var(--primary-color);\n    color: var(--primary-color);\n}\n\n.btn-outline:hover {\n    background: var(--primary-color);\n    color: white;\n}\n\n.form-group {\n    margin-bottom: 20px;\n}\n\n.form-label {\n    display: block;\n    margin-bottom: 8px;\n    font-weight: 600;\n    color: var(--text-dark);\n}\n\n.form-control {\n    width: 100%;\n    padding: 12px 16px;\n    border: 2px solid #e0e0e0;\n    border-radius: var(--border-radius-sm);\n    font-size: 1em;\n    transition: var(--transition);\n    font-family: inherit;\n}\n\n.form-control:focus {\n    outline: none;\n    border-color: var(--primary-color);\n    box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.1);\n}\n\n.form-control.error {\n    border-color: var(--danger-color);\n}\n\n.form-error {\n    color: var(--danger-color);\n    font-size: 0.9em;\n    margin-top: 5px;\n}\n\n.alert {\n    padding: 15px 20px;\n    border-radius: var(--border-radius-sm);\n    margin-bottom: 20px;\n    display: flex;\n    align-items: center;\n    gap: 10px;\n}\n\n.alert-success {\n    background: #e8f5e9;\n    color: #2e7d32;\n    border-left: 4px solid var(--success-color);\n}\n\n.alert-error {\n    background: #ffebee;\n    color: #c62828;\n    border-left: 4px solid var(--danger-color);\n}\n\n.alert-info {\n    background: #e3f2fd;\n    color: #1565c0;\n    border-left: 4px solid var(--info-color);\n}\n\n.alert-warning {\n    background: #fff3e0;\n    color: #e65100;\n    border-left: 4px solid var(--warning-color);\n}\n\n.upload-area {\n    border: 3px dashed var(--primary-color);\n    border-radius: var(--border-radius);\n    padding: 40px;\n    text-align: center;\n    transition: var(--transition);\n    cursor: pointer;\n    background: var(--bg-light);\n}\n\n.upload-area:hover,\n.upload-area.dragover {\n    border-color: var(--primary-dark);\n    background: #e8ecff;\n    transform: scale(1.02);\n}\n\n.upload-icon {\n    font-size: 4em;\n    color: var(--primary-color);\n    margin-bottom: 20px;\n}\n\n.badge {\n    display: inline-block;\n    padding: 5px 15px;\n    border-radius: 20px;\n    font-weight: 600;\n    font-size: 0.9em;\n}\n\n.badge-demo {\n    background: #fff3cd;\n    color: #856404;\n}\n\n.badge-trained {\n    background: #d4edda;\n    color: #155724;\n}\n\n.badge-genuine {\n    background: #d4edda;\n    color: #155724;\n}\n\n.badge-fake {\n    background: #ffebee;\n    color: #c62828;\n}\n\n.loading {\n    display: flex;\n    flex-direction: column;\n    align-items: center;\n    justify-content: center;\n    padding: 40px;\n}\n\n.spinner {\n    border: 4px solid #f3f3f3;\n    border-top: 4px solid var(--primary-color);\n    border-radius: 50%;\n    width: 50px;\n    height: 50px;\n    animation: spin 1s linear infinite;\n}\n\n@keyframes spin {\n    0% { transform: rotate(0deg); }\n    100% { transform: rotate(360deg); }\n}\n\n.grid {\n    display: grid;\n    gap: 20px;\n}\n\n.grid-2 {\n    grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));\n}\n\n.grid-3 {\n    grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));\n}\n\n.text-center {\n    text-align: center;\n}\n\n.mb-2 { margin-bottom: 1rem; }\n.mb-3 { margin-bottom: 1.5rem; }\n.mb-4 { margin-bottom: 2rem; }\n.mt-2 { margin-top: 1rem; }\n.mt-3 { margin-top: 1.5rem; }\n.mt-4 { margin-top: 2rem; }\n\n.auth-container {\n    max-width: 450px;\n    margin: 50px auto;\n}\n\n.auth-card {\n    background: var(--bg-white);\n    border-radius: var(--border-radius-lg);\n    padding: 40px;\n    box-shadow: var(--shadow-lg);\n}\n\n.auth-header {\n    text-align: center;\n    margin-bottom: 30px;\n}\n\n.auth-icon {\n    font-size: 3em;\n    margin-bottom: 15px;\n}\n\n.auth-links {\n    text-align: center;\n    margin-top: 20px;\n    color: var(--text-medium);\n}\n\n.auth-links a {\n    color: var(--primary-color);\n    text-decoration: none;\n    font-weight: 600;\n}\n\n.auth-links a:hover {\n    text-decoration: underline;\n}\n\n@media (max-width: 768px) {\n    .navbar-menu {\n        gap: 10px;\n    }\n    \n    .navbar-menu a {\n        padding: 6px 12px;\n        font-size: 0.9em;\n    }\n    \n    .card {\n        padding: 20px;\n    }\n    \n    .card-title {\n        font-size: 1.5em;\n    }\n}\n","size_bytes":7494},"CounterfeitGuard/create_dataset.py":{"content":"\"\"\"\nCreate a synthetic currency image dataset for training\nGenerates realistic-looking currency note images for demonstration\n\"\"\"\nimport numpy as np\nfrom PIL import Image, ImageDraw, ImageFont, ImageFilter\nimport os\nimport random\nfrom pathlib import Path\n\ndef create_currency_image(genuine=True, seed=None):\n    \"\"\"\n    Generate a synthetic currency note image\n    \n    Args:\n        genuine: If True, create genuine note, else create fake note\n        seed: Random seed for reproducibility\n    \n    Returns:\n        PIL Image\n    \"\"\"\n    if seed is not None:\n        random.seed(seed)\n        np.random.seed(seed)\n    \n    # Create base image (224x224 for MobileNet)\n    width, height = 448, 224\n    \n    # Base colors\n    if genuine:\n        # Genuine notes have more consistent, vibrant colors\n        base_color = random.choice([\n            (34, 139, 34),   # Forest green\n            (25, 25, 112),   # Midnight blue\n            (139, 69, 19),   # Saddle brown\n            (128, 0, 128),   # Purple\n        ])\n        texture_intensity = 0.05\n        watermark_alpha = 180\n    else:\n        # Fake notes have slightly off colors and poor quality\n        base_color = random.choice([\n            (50, 150, 50),   # Slightly off green\n            (40, 40, 120),   # Slightly off blue\n            (150, 80, 30),   # Slightly off brown\n            (140, 10, 140),  # Slightly off purple\n        ])\n        texture_intensity = 0.15\n        watermark_alpha = 100\n    \n    # Create base with noise\n    img = Image.new('RGB', (width, height), base_color)\n    pixels = np.array(img)\n    \n    # Add texture noise\n    noise = np.random.normal(0, texture_intensity * 255, pixels.shape)\n    pixels = np.clip(pixels + noise, 0, 255).astype(np.uint8)\n    img = Image.fromarray(pixels)\n    \n    draw = ImageDraw.Draw(img, 'RGBA')\n    \n    # Add geometric patterns\n    num_lines = 15 if genuine else random.randint(8, 12)\n    for i in range(num_lines):\n        x = random.randint(0, width)\n        color = tuple(np.clip(np.array(base_color) + np.random.randint(-30, 30, 3), 0, 255).tolist())\n        draw.line([(x, 0), (x, height)], fill=color, width=1)\n    \n    # Add circles (security features)\n    num_circles = random.randint(3, 6) if genuine else random.randint(1, 3)\n    for _ in range(num_circles):\n        x, y = random.randint(20, width-20), random.randint(20, height-20)\n        r = random.randint(10, 30)\n        circle_color = tuple(np.clip(np.array(base_color) + 50, 0, 255).tolist())\n        draw.ellipse([x-r, y-r, x+r, y+r], outline=circle_color, width=2)\n    \n    # Add denomination number\n    denomination = random.choice([10, 20, 50, 100])\n    try:\n        font_size = 60 if genuine else random.randint(50, 65)\n        \n        # Add number in corners\n        for pos in [(30, 30), (width-80, 30), (30, height-90), (width-80, height-90)]:\n            text_color = (255, 255, 255, watermark_alpha)\n            shadow_offset = 2\n            # Shadow\n            draw.text((pos[0]+shadow_offset, pos[1]+shadow_offset), str(denomination), \n                     fill=(0, 0, 0, watermark_alpha//2))\n            # Main text\n            draw.text(pos, str(denomination), fill=text_color)\n    except:\n        pass\n    \n    # Add watermark patterns\n    if genuine:\n        # Genuine notes have clear, consistent watermarks\n        for i in range(5):\n            x = width // 6 * (i + 1)\n            draw.ellipse([x-15, height//2-15, x+15, height//2+15], \n                        outline=(255, 255, 255, 150), width=2)\n    else:\n        # Fake notes have irregular watermarks\n        for i in range(random.randint(2, 4)):\n            x = random.randint(50, width-50)\n            y = random.randint(50, height-50)\n            draw.ellipse([x-10, y-10, x+10, y+10], \n                        outline=(255, 255, 255, 80), width=1)\n    \n    # Add some blur to fake notes\n    if not genuine:\n        img = img.filter(ImageFilter.GaussianBlur(radius=random.uniform(0.3, 0.8)))\n    \n    # Resize to 224x224\n    img = img.resize((224, 224), Image.Resampling.LANCZOS)\n    \n    # Add final quality variations\n    if not genuine:\n        # Reduce quality slightly for fake notes\n        enhancer = np.random.uniform(0.85, 0.95)\n        pixels = np.array(img).astype(float)\n        pixels = np.clip(pixels * enhancer, 0, 255).astype(np.uint8)\n        img = Image.fromarray(pixels)\n    \n    return img\n\ndef create_dataset(num_images_per_class=150, train_split=0.8):\n    \"\"\"\n    Create a complete dataset with train/val splits\n    \n    Args:\n        num_images_per_class: Number of images per class (genuine/fake)\n        train_split: Proportion for training set\n    \"\"\"\n    print(\"Creating synthetic currency dataset...\")\n    print(f\"Generating {num_images_per_class} genuine and {num_images_per_class} fake notes\")\n    \n    # Create directory structure\n    dataset_dir = Path('dataset')\n    for split in ['train', 'val']:\n        for category in ['fake', 'genuine']:\n            (dataset_dir / split / category).mkdir(parents=True, exist_ok=True)\n    \n    # Determine split\n    num_train = int(num_images_per_class * train_split)\n    num_val = num_images_per_class - num_train\n    \n    # Generate images\n    for category, is_genuine in [('genuine', True), ('fake', False)]:\n        print(f\"\\nGenerating {category} notes...\")\n        \n        # Training images\n        for i in range(num_train):\n            img = create_currency_image(genuine=is_genuine, seed=i)\n            img.save(dataset_dir / 'train' / category / f'{category}_{i:04d}.jpg', quality=95)\n            if (i + 1) % 50 == 0:\n                print(f\"  Generated {i+1}/{num_train} training images\")\n        \n        # Validation images\n        for i in range(num_val):\n            img = create_currency_image(genuine=is_genuine, seed=num_train + i)\n            img.save(dataset_dir / 'val' / category / f'{category}_{i:04d}.jpg', quality=95)\n        \n        print(f\"  Completed {category}: {num_train} train, {num_val} val\")\n    \n    # Print summary\n    print(\"\\n\" + \"=\"*60)\n    print(\"Dataset created successfully!\")\n    print(\"=\"*60)\n    print(f\"Train - Genuine: {num_train} images\")\n    print(f\"Train - Fake: {num_train} images\")\n    print(f\"Val - Genuine: {num_val} images\")\n    print(f\"Val - Fake: {num_val} images\")\n    print(f\"Total: {num_images_per_class * 2} images\")\n    print(\"\\nDataset structure:\")\n    print(\"  dataset/train/genuine/\")\n    print(\"  dataset/train/fake/\")\n    print(\"  dataset/val/genuine/\")\n    print(\"  dataset/val/fake/\")\n\nif __name__ == '__main__':\n    # Create dataset with 300 images (150 genuine + 150 fake)\n    create_dataset(num_images_per_class=150, train_split=0.8)\n    print(\"\\nYou can now run: python train_model.py\")\n","size_bytes":6709},"train_500_only.py":{"content":"\n\"\"\"\nTrain model specifically for 500 Rupee notes detection\n\"\"\"\nimport os\nimport shutil\nfrom pathlib import Path\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\n\ndef create_500_dataset():\n    \"\"\"Create dataset with only 500 rupee notes\"\"\"\n    print(\"=\"*70)\n    print(\"CREATING 500 RUPEE DATASET\")\n    print(\"=\"*70)\n    \n    # Source directories\n    genuine_source = \"Test Images/genuine\"\n    fake_source = \"Test Images/fake\"\n    \n    # Destination\n    dataset_root = \"dataset_500_only\"\n    train_dir = os.path.join(dataset_root, \"train\")\n    val_dir = os.path.join(dataset_root, \"val\")\n    \n    # Create structure\n    for split in ['train', 'val']:\n        for class_name in ['fake', 'genuine']:\n            os.makedirs(os.path.join(dataset_root, split, class_name), exist_ok=True)\n    \n    # Get 500 rupee images (filter by filename containing \"500\")\n    genuine_images = [f for f in os.listdir(genuine_source) \n                     if f.endswith(('.jpg', '.png', '.jpeg')) and '500' in f]\n    # For fake, we'll use all since they're counterfeit training samples\n    fake_images = [f for f in os.listdir(fake_source) \n                  if f.endswith(('.jpg', '.png', '.jpeg'))]\n    \n    print(f\"\\nFound {len(genuine_images)} genuine 500 rupee images\")\n    print(f\"Found {len(fake_images)} fake currency images\")\n    \n    # Split: 80% train, 20% val\n    genuine_split = int(len(genuine_images) * 0.8)\n    fake_split = int(len(fake_images) * 0.8)\n    \n    genuine_train = genuine_images[:genuine_split]\n    genuine_val = genuine_images[genuine_split:]\n    fake_train = fake_images[:fake_split]\n    fake_val = fake_images[fake_split:]\n    \n    print(f\"\\nTrain: {len(genuine_train)} genuine + {len(fake_train)} fake\")\n    print(f\"Val: {len(genuine_val)} genuine + {len(fake_val)} fake\")\n    \n    # Copy images\n    for img in genuine_train:\n        shutil.copy2(os.path.join(genuine_source, img), \n                    os.path.join(train_dir, 'genuine', img))\n    \n    for img in fake_train:\n        shutil.copy2(os.path.join(fake_source, img), \n                    os.path.join(train_dir, 'fake', img))\n    \n    for img in genuine_val:\n        shutil.copy2(os.path.join(genuine_source, img), \n                    os.path.join(val_dir, 'genuine', img))\n    \n    for img in fake_val:\n        shutil.copy2(os.path.join(fake_source, img), \n                    os.path.join(val_dir, 'fake', img))\n    \n    print(\"\\n✓ Dataset created successfully!\")\n    return dataset_root\n\ndef create_model(input_shape=(224, 224, 3), num_classes=2):\n    \"\"\"Create MobileNetV2-based model\"\"\"\n    print(\"\\nCreating model...\")\n    \n    base_model = MobileNetV2(\n        input_shape=input_shape,\n        include_top=False,\n        weights='imagenet'\n    )\n    base_model.trainable = False\n    \n    inputs = keras.Input(shape=input_shape)\n    x = keras.applications.mobilenet_v2.preprocess_input(inputs)\n    x = base_model(x, training=False)\n    x = layers.GlobalAveragePooling2D()(x)\n    x = layers.Dropout(0.5)(x)\n    x = layers.Dense(256, activation='relu')(x)\n    x = layers.Dropout(0.3)(x)\n    x = layers.Dense(128, activation='relu')(x)\n    outputs = layers.Dense(num_classes, activation='softmax')(x)\n    \n    model = keras.Model(inputs, outputs)\n    model.compile(\n        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    \n    print(\"✓ Model created\")\n    return model\n\ndef fine_tune_model(model, num_layers=20):\n    \"\"\"Fine-tune by unfreezing layers\"\"\"\n    print(f\"\\nFine-tuning: unfreezing last {num_layers} layers...\")\n    \n    base_model = None\n    for layer in model.layers:\n        if 'mobilenet' in layer.name.lower():\n            base_model = layer\n            break\n    \n    if base_model:\n        base_model.trainable = True\n        for layer in base_model.layers[:-num_layers]:\n            layer.trainable = False\n        \n        model.compile(\n            optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n            loss='categorical_crossentropy',\n            metrics=['accuracy']\n        )\n    \n    print(\"✓ Model ready for fine-tuning\")\n    return model\n\ndef train_500_model():\n    \"\"\"Train model for 500 rupee notes\"\"\"\n    print(\"=\"*70)\n    print(\"TRAINING MODEL FOR 500 RUPEE NOTES\")\n    print(\"=\"*70)\n    \n    # Create dataset\n    dataset_root = create_500_dataset()\n    train_dir = os.path.join(dataset_root, \"train\")\n    val_dir = os.path.join(dataset_root, \"val\")\n    \n    # Create model\n    model = create_model()\n    \n    # Data generators\n    train_datagen = ImageDataGenerator(\n        rotation_range=10,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        shear_range=0.1,\n        zoom_range=0.1,\n        horizontal_flip=True,\n        fill_mode='nearest'\n    )\n    \n    val_datagen = ImageDataGenerator()\n    \n    train_generator = train_datagen.flow_from_directory(\n        train_dir,\n        target_size=(224, 224),\n        batch_size=16,\n        class_mode='categorical',\n        shuffle=True\n    )\n    \n    val_generator = val_datagen.flow_from_directory(\n        val_dir,\n        target_size=(224, 224),\n        batch_size=16,\n        class_mode='categorical',\n        shuffle=False\n    )\n    \n    print(f\"\\nDataset info:\")\n    print(f\"  Training samples: {train_generator.samples}\")\n    print(f\"  Validation samples: {val_generator.samples}\")\n    print(f\"  Classes: {train_generator.class_indices}\")\n    \n    # Create model directory\n    os.makedirs('model', exist_ok=True)\n    os.makedirs('CounterfeitGuard/model', exist_ok=True)\n    \n    # Callbacks\n    callbacks = [\n        keras.callbacks.ModelCheckpoint(\n            'model/currency_detector_500_best.h5',\n            monitor='val_accuracy',\n            save_best_only=True,\n            verbose=1\n        ),\n        keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=5,\n            restore_best_weights=True,\n            verbose=1\n        ),\n        keras.callbacks.ReduceLROnPlateau(\n            monitor='val_loss',\n            factor=0.5,\n            patience=3,\n            min_lr=1e-7,\n            verbose=1\n        )\n    ]\n    \n    # Phase 1: Initial training\n    print(\"\\n\" + \"=\"*70)\n    print(\"PHASE 1: Initial Training\")\n    print(\"=\"*70)\n    \n    history = model.fit(\n        train_generator,\n        epochs=15,\n        validation_data=val_generator,\n        callbacks=callbacks,\n        verbose=1\n    )\n    \n    # Phase 2: Fine-tuning\n    print(\"\\n\" + \"=\"*70)\n    print(\"PHASE 2: Fine-Tuning\")\n    print(\"=\"*70)\n    \n    model = fine_tune_model(model)\n    \n    history_fine = model.fit(\n        train_generator,\n        epochs=10,\n        validation_data=val_generator,\n        callbacks=callbacks,\n        verbose=1\n    )\n    \n    # Save final model\n    model.save('model/currency_detector.h5')\n    model.save('CounterfeitGuard/model/currency_detector.h5')\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"TRAINING COMPLETE!\")\n    print(\"=\"*70)\n    \n    # Evaluate\n    val_loss, val_accuracy = model.evaluate(val_generator, verbose=0)\n    print(f\"\\nFinal Validation Accuracy: {val_accuracy*100:.2f}%\")\n    print(f\"Final Validation Loss: {val_loss:.4f}\")\n    \n    print(\"\\nModel saved to:\")\n    print(\"  • model/currency_detector.h5\")\n    print(\"  • CounterfeitGuard/model/currency_detector.h5\")\n    print(\"=\"*70)\n    \n    # Plot history\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n    \n    ax1.plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n    ax1.plot(history.history['val_accuracy'], label='Val Accuracy', linewidth=2)\n    if history_fine:\n        offset = len(history.history['accuracy'])\n        ax1.plot(range(offset, offset + len(history_fine.history['accuracy'])), \n                 history_fine.history['accuracy'], label='Train Acc (Fine-tune)', linewidth=2)\n        ax1.plot(range(offset, offset + len(history_fine.history['val_accuracy'])), \n                 history_fine.history['val_accuracy'], label='Val Acc (Fine-tune)', linewidth=2)\n    ax1.set_xlabel('Epoch')\n    ax1.set_ylabel('Accuracy')\n    ax1.set_title('Model Accuracy - 500 Rupee Training')\n    ax1.legend()\n    ax1.grid(True, alpha=0.3)\n    \n    ax2.plot(history.history['loss'], label='Train Loss', linewidth=2)\n    ax2.plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n    if history_fine:\n        offset = len(history.history['loss'])\n        ax2.plot(range(offset, offset + len(history_fine.history['loss'])), \n                 history_fine.history['loss'], label='Train Loss (Fine-tune)', linewidth=2)\n        ax2.plot(range(offset, offset + len(history_fine.history['val_loss'])), \n                 history_fine.history['val_loss'], label='Val Loss (Fine-tune)', linewidth=2)\n    ax2.set_xlabel('Epoch')\n    ax2.set_ylabel('Loss')\n    ax2.set_title('Model Loss - 500 Rupee Training')\n    ax2.legend()\n    ax2.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.savefig('model/training_history_500.png', dpi=150)\n    print(f\"\\n✓ Training plot saved to model/training_history_500.png\")\n\nif __name__ == '__main__':\n    train_500_model()\n","size_bytes":9297},"scripts/complete_training.py":{"content":"\"\"\"\nComplete training by running fine-tuning on the already-trained model\n\"\"\"\nimport os\nfrom train_indian_currency_model import fine_tune_model, create_data_generators, plot_training_history\nfrom tensorflow import keras\n\nprint(\"=\"*70)\nprint(\"COMPLETING TRAINING: Fine-Tuning Phase\")\nprint(\"=\"*70)\n\n# Load the best model from Phase 1\nmodel_path = 'model/indian_currency_detector_best.h5'\nprint(f\"\\nLoading model from {model_path}...\")\nmodel = keras.models.load_model(model_path)\nprint(\"✓ Model loaded successfully\")\n\n# Create data generators\ntrain_dir = 'indian_currency_dataset/train'\nval_dir = 'indian_currency_dataset/val'\nbatch_size = 16\n\nprint(\"\\nCreating data generators...\")\ntrain_generator, val_generator = create_data_generators(\n    train_dir, val_dir, batch_size\n)\n\nprint(f\"\\nDataset:\")\nprint(f\"  Training samples: {train_generator.samples}\")\nprint(f\"  Validation samples: {val_generator.samples}\")\nprint(f\"  Classes: {train_generator.class_indices}\")\n\n# Evaluate initial model\nprint(\"\\n\" + \"=\"*70)\nprint(\"Initial Model Performance (Before Fine-Tuning)\")\nprint(\"=\"*70)\ninitial_val_loss, initial_val_accuracy = model.evaluate(val_generator, verbose=0)\nprint(f\"Validation Accuracy: {initial_val_accuracy*100:.2f}%\")\nprint(f\"Validation Loss: {initial_val_loss:.4f}\")\n\n# Fine-tune the model\nprint(\"\\n\" + \"=\"*70)\nprint(\"PHASE 2: Fine-Tuning (Unfreezing Last Layers)\")\nprint(\"=\"*70)\n\nmodel = fine_tune_model(model, num_layers_to_unfreeze=20)\n\n# Callbacks\ncallbacks = [\n    keras.callbacks.ModelCheckpoint(\n        'model/indian_currency_detector_best.h5',\n        monitor='val_accuracy',\n        save_best_only=True,\n        verbose=1\n    ),\n    keras.callbacks.EarlyStopping(\n        monitor='val_loss',\n        patience=5,\n        restore_best_weights=True,\n        verbose=1\n    ),\n    keras.callbacks.ReduceLROnPlateau(\n        monitor='val_loss',\n        factor=0.5,\n        patience=3,\n        min_lr=1e-7,\n        verbose=1\n    )\n]\n\n# Fine-tune\nhistory_fine = model.fit(\n    train_generator,\n    epochs=10,\n    validation_data=val_generator,\n    callbacks=callbacks,\n    verbose=1\n)\n\n# Save final model\nmodel.save('model/indian_currency_detector.h5')\nprint(\"\\n✓ Final model saved to model/indian_currency_detector.h5\")\n\n# Also save to CounterfeitGuard directory\nos.makedirs('CounterfeitGuard/model', exist_ok=True)\nmodel.save('CounterfeitGuard/model/currency_detector.h5')\nprint(\"✓ Model copied to CounterfeitGuard/model/currency_detector.h5\")\n\n# Final evaluation\nprint(\"\\n\" + \"=\"*70)\nprint(\"FINAL EVALUATION\")\nprint(\"=\"*70)\n\nval_loss, val_accuracy = model.evaluate(val_generator, verbose=0)\nprint(f\"Validation Accuracy: {val_accuracy*100:.2f}%\")\nprint(f\"Validation Loss: {val_loss:.4f}\")\n\nprint(f\"\\nImprovement: {(val_accuracy - initial_val_accuracy)*100:+.2f}%\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"TRAINING COMPLETE!\")\nprint(\"=\"*70)\nprint(\"Model saved to:\")\nprint(\"  • model/indian_currency_detector.h5\")\nprint(\"  • model/indian_currency_detector_best.h5\")\nprint(\"  • CounterfeitGuard/model/currency_detector.h5\")\nprint(\"=\"*70)\n","size_bytes":3047},"main.py":{"content":"\nfrom CounterfeitGuard.app import app, db\n\nif __name__ == \"__main__\":\n    # Initialize database tables\n    with app.app_context():\n        db.create_all()\n        print(\"Database initialized successfully\")\n    \n    # Run the Flask app\n    app.run(host=\"0.0.0.0\", port=5000, debug=True)\n","size_bytes":286},"scripts/download_kaggle_dataset.py":{"content":"\"\"\"\nDownload and prepare Kaggle dataset for Indian currency counterfeit detection\n\"\"\"\nimport os\nimport subprocess\nimport zipfile\nimport shutil\nfrom pathlib import Path\n\ndef setup_kaggle_credentials():\n    \"\"\"Set up Kaggle credentials from environment variables\"\"\"\n    kaggle_dir = Path.home() / '.kaggle'\n    kaggle_dir.mkdir(exist_ok=True)\n    \n    kaggle_json = {\n        \"username\": os.environ.get('KAGGLE_USERNAME'),\n        \"key\": os.environ.get('KAGGLE_KEY')\n    }\n    \n    kaggle_json_path = kaggle_dir / 'kaggle.json'\n    import json\n    with open(kaggle_json_path, 'w') as f:\n        json.dump(kaggle_json, f)\n    \n    # Set proper permissions\n    os.chmod(kaggle_json_path, 0o600)\n    print(f\"Kaggle credentials set up at {kaggle_json_path}\")\n\ndef download_dataset():\n    \"\"\"Download the fake currency dataset from Kaggle\"\"\"\n    print(\"\\n\" + \"=\"*60)\n    print(\"Downloading Indian Fake Currency Dataset from Kaggle...\")\n    print(\"=\"*60 + \"\\n\")\n    \n    dataset_name = \"lekhansaathvik/fake-currency-dataset\"\n    download_path = \"./kaggle_dataset\"\n    \n    # Create download directory\n    os.makedirs(download_path, exist_ok=True)\n    \n    # Download using Kaggle API\n    try:\n        subprocess.run([\n            \"kaggle\", \"datasets\", \"download\", \n            \"-d\", dataset_name,\n            \"-p\", download_path,\n            \"--unzip\"\n        ], check=True)\n        print(f\"\\n✓ Dataset downloaded successfully to {download_path}\")\n        return download_path\n    except subprocess.CalledProcessError as e:\n        print(f\"Error downloading dataset: {e}\")\n        return None\n\ndef organize_dataset(download_path):\n    \"\"\"Organize the dataset into train/val structure\"\"\"\n    print(\"\\n\" + \"=\"*60)\n    print(\"Organizing dataset for training...\")\n    print(\"=\"*60 + \"\\n\")\n    \n    # Check what files are in the download directory\n    print(f\"Contents of {download_path}:\")\n    for root, dirs, files in os.walk(download_path):\n        level = root.replace(download_path, '').count(os.sep)\n        indent = ' ' * 2 * level\n        print(f'{indent}{os.path.basename(root)}/')\n        subindent = ' ' * 2 * (level + 1)\n        for file in files[:5]:  # Show first 5 files\n            print(f'{subindent}{file}')\n        if len(files) > 5:\n            print(f'{subindent}... and {len(files) - 5} more files')\n    \n    # Look for train and validation directories\n    train_dir = Path(\"dataset/train\")\n    val_dir = Path(\"dataset/val\")\n    \n    # Create directories\n    for split in ['train', 'val']:\n        for category in ['fake', 'genuine']:\n            os.makedirs(f\"dataset/{split}/{category}\", exist_ok=True)\n    \n    # Find and organize the files\n    download_path = Path(download_path)\n    \n    # Try to find the dataset structure\n    possible_paths = [\n        download_path / \"train\",\n        download_path / \"Train\",\n        download_path / \"training\",\n        download_path,\n    ]\n    \n    # Look for image files and organize them\n    train_fake = list(download_path.rglob(\"*fake*.png\")) + list(download_path.rglob(\"*fake*.jpg\")) + list(download_path.rglob(\"*Fake*.png\"))\n    train_genuine = list(download_path.rglob(\"*genuine*.png\")) + list(download_path.rglob(\"*genuine*.jpg\")) + list(download_path.rglob(\"*real*.png\"))\n    \n    # If we can't find organized structure, try the existing indian_currency_dataset\n    if os.path.exists(\"indian_currency_dataset/train\"):\n        print(\"\\nFound existing indian_currency_dataset! Using that instead...\")\n        \n        # Copy from indian_currency_dataset to dataset\n        if os.path.exists(\"indian_currency_dataset/train/fake\"):\n            src = \"indian_currency_dataset/train\"\n            dst = \"dataset/train\"\n            if os.path.exists(dst):\n                shutil.rmtree(dst)\n            shutil.copytree(src, dst)\n            print(f\"✓ Copied training data from indian_currency_dataset\")\n        \n        if os.path.exists(\"indian_currency_dataset/val/fake\"):\n            src = \"indian_currency_dataset/val\"\n            dst = \"dataset/val\"\n            if os.path.exists(dst):\n                shutil.rmtree(dst)\n            shutil.copytree(src, dst)\n            print(f\"✓ Copied validation data from indian_currency_dataset\")\n        \n        return True\n    \n    # If no structured data found, try to organize the downloaded files\n    print(f\"\\nFound {len(train_fake)} fake images and {len(train_genuine)} genuine images\")\n    \n    if len(train_fake) == 0 and len(train_genuine) == 0:\n        print(\"\\nWarning: Could not find fake/genuine images in Kaggle dataset\")\n        print(\"Please check the dataset structure manually\")\n        return False\n    \n    # Split 80-20 for train/val\n    from sklearn.model_selection import train_test_split\n    \n    if train_fake:\n        fake_train, fake_val = train_test_split(train_fake, test_size=0.2, random_state=42)\n        \n        for img_path in fake_train:\n            shutil.copy(img_path, f\"dataset/train/fake/{img_path.name}\")\n        \n        for img_path in fake_val:\n            shutil.copy(img_path, f\"dataset/val/fake/{img_path.name}\")\n        \n        print(f\"✓ Organized {len(fake_train)} fake training images\")\n        print(f\"✓ Organized {len(fake_val)} fake validation images\")\n    \n    if train_genuine:\n        genuine_train, genuine_val = train_test_split(train_genuine, test_size=0.2, random_state=42)\n        \n        for img_path in genuine_train:\n            shutil.copy(img_path, f\"dataset/train/genuine/{img_path.name}\")\n        \n        for img_path in genuine_val:\n            shutil.copy(img_path, f\"dataset/val/genuine/{img_path.name}\")\n        \n        print(f\"✓ Organized {len(genuine_train)} genuine training images\")\n        print(f\"✓ Organized {len(genuine_val)} genuine validation images\")\n    \n    return True\n\ndef print_dataset_summary():\n    \"\"\"Print summary of organized dataset\"\"\"\n    print(\"\\n\" + \"=\"*60)\n    print(\"Dataset Summary\")\n    print(\"=\"*60 + \"\\n\")\n    \n    for split in ['train', 'val']:\n        for category in ['fake', 'genuine']:\n            path = f\"dataset/{split}/{category}\"\n            if os.path.exists(path):\n                count = len([f for f in os.listdir(path) if f.endswith(('.png', '.jpg', '.jpeg'))])\n                print(f\"{split.capitalize():12} {category.capitalize():10}: {count:4} images\")\n            else:\n                print(f\"{split.capitalize():12} {category.capitalize():10}: Directory not found\")\n    \n    print(\"\\n✓ Dataset is ready for training!\")\n    print(\"Run: uv run python train_indian_currency_model.py\")\n\nif __name__ == '__main__':\n    # Set up Kaggle credentials\n    setup_kaggle_credentials()\n    \n    # Download dataset\n    download_path = download_dataset()\n    \n    if download_path:\n        # Organize dataset\n        success = organize_dataset(download_path)\n        \n        if success:\n            # Print summary\n            print_dataset_summary()\n        else:\n            print(\"\\nNote: Using existing indian_currency_dataset if available\")\n            print_dataset_summary()\n    else:\n        print(\"\\nFailed to download dataset. Checking for existing dataset...\")\n        organize_dataset(\"./\")\n        print_dataset_summary()\n","size_bytes":7164},"pyproject.toml":{"content":"[project]\nname = \"repl-nix-workspace\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nrequires-python = \">=3.11\"\ndependencies = [\n    \"email-validator>=2.3.0\",\n    \"flask==3.0.0\",\n    \"flask-login>=0.6.3\",\n    \"flask-sqlalchemy>=3.1.1\",\n    \"gunicorn>=23.0.0\",\n    \"kaggle>=1.7.4.5\",\n    \"matplotlib==3.8.2\",\n    \"numpy==1.24.3\",\n    \"opencv-python==4.8.1.78\",\n    \"pillow==10.1.0\",\n    \"psycopg2-binary>=2.9.11\",\n    \"requests>=2.32.5\",\n    \"scikit-learn>=1.7.2\",\n    \"scipy>=1.15.3\",\n    \"seaborn>=0.13.2\",\n    \"tensorflow==2.15.0\",\n    \"werkzeug==3.0.1\",\n]\n","size_bytes":572},"CounterfeitGuard/app.py":{"content":"\"\"\"\nFlask API for Fake Currency Detection with Grad-CAM Visualization\n\"\"\"\nfrom flask import Flask, request, jsonify, render_template, send_file, redirect, url_for, flash\nfrom flask_sqlalchemy import SQLAlchemy\nfrom flask_login import LoginManager, UserMixin, login_user, logout_user, login_required, current_user\nfrom werkzeug.security import generate_password_hash, check_password_hash\nimport tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\nimport cv2\nfrom PIL import Image\nimport os\nimport io\nimport tempfile\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\nfrom werkzeug.utils import secure_filename\n\napp = Flask(__name__)\napp.config['SECRET_KEY'] = os.environ.get('SECRET_KEY', 'dev-secret-key-change-in-production')\napp.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB max file size\n# Use temporary directory for uploads (not stored in project folder)\napp.config['UPLOAD_FOLDER'] = os.path.join(tempfile.gettempdir(), 'currency_uploads')\n\n# Use absolute path for database\nbasedir = os.path.abspath(os.path.dirname(__file__))\ndb_path = os.path.join(basedir, 'instance', 'currency_detector.db')\napp.config['SQLALCHEMY_DATABASE_URI'] = f'sqlite:///{db_path}'\napp.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False\n\n# Ensure instance folder exists\nos.makedirs(os.path.join(basedir, 'instance'), exist_ok=True)\nALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg'}\n\ndb = SQLAlchemy(app)\nlogin_manager = LoginManager()\nlogin_manager.init_app(app)\nlogin_manager.login_view = 'login'\nlogin_manager.login_message = 'Please login to access this page.'\nlogin_manager.login_message_category = 'info'\n\n\nclass User(UserMixin, db.Model):\n    id = db.Column(db.Integer, primary_key=True)\n    username = db.Column(db.String(80), unique=True, nullable=False)\n    password_hash = db.Column(db.String(200), nullable=False)\n    \n    def set_password(self, password):\n        self.password_hash = generate_password_hash(password)\n    \n    def check_password(self, password):\n        return check_password_hash(self.password_hash, password)\n\n\n@login_manager.user_loader\ndef load_user(user_id):\n    return User.query.get(int(user_id))\n\n# Create uploads directory\nos.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)\n\n# Global variable to store model\nmodel = None\nclass_names = ['Fake', 'Genuine']\n\n\ndef allowed_file(filename):\n    \"\"\"Check if file extension is allowed\"\"\"\n    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n\n\ndef load_model_file():\n    \"\"\"Load the trained model\"\"\"\n    global model\n    \n    # Only load if not already loaded\n    if model is not None:\n        return\n    \n    # Use absolute path for model\n    model_path = os.path.join(basedir, 'model', 'currency_detector.h5')\n    \n    if os.path.exists(model_path):\n        model = keras.models.load_model(model_path)\n        print(f\"Model loaded successfully from {model_path}\")\n    else:\n        # Create a simple demo model if no trained model exists\n        print(f\"No trained model found at {model_path}. Creating demo model...\")\n        from CounterfeitGuard.model import create_model\n        model = create_model()\n        print(\"Demo model created. Train a real model for better accuracy.\")\n\n\n# Load model on app initialization\nwith app.app_context():\n    load_model_file()\n\n\ndef preprocess_image(image_path, target_size=(224, 224)):\n    \"\"\"Preprocess image for model prediction\"\"\"\n    img = keras.preprocessing.image.load_img(image_path, target_size=target_size)\n    img_array = keras.preprocessing.image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0)\n    img_array = keras.applications.mobilenet_v2.preprocess_input(img_array)\n    return img_array, img\n\n\ndef make_gradcam_heatmap(img_array, model, last_conv_layer_name=None, pred_index=None):\n    \"\"\"\n    Generate Grad-CAM heatmap for model interpretability\n    \n    Args:\n        img_array: Preprocessed image array\n        model: Trained model\n        last_conv_layer_name: Name of last convolutional layer (auto-detected if None)\n        pred_index: Class index for which to compute Grad-CAM\n    \n    Returns:\n        Heatmap array\n    \"\"\"\n    # Find the MobileNetV2 base model layer\n    base_model_layer = None\n    for layer in model.layers:\n        if 'mobilenet' in layer.name.lower():\n            base_model_layer = layer\n            break\n    \n    # Get the last convolutional layer from the base model\n    last_conv_layer = None\n    if base_model_layer is not None:\n        # Try to find the last convolutional layer in the base model\n        try:\n            last_conv_layer = base_model_layer.get_layer('out_relu')\n        except:\n            try:\n                last_conv_layer = base_model_layer.get_layer('Conv_1')\n            except:\n                # Find any conv layer\n                for layer in reversed(base_model_layer.layers):\n                    if 'conv' in layer.name.lower() and hasattr(layer, 'output'):\n                        last_conv_layer = layer\n                        break\n    \n    # If we couldn't find a conv layer, use global average pooling as fallback\n    if last_conv_layer is None:\n        try:\n            target_layer = model.get_layer('global_average_pooling2d')\n        except:\n            # Just use the layer before the final dense layer\n            target_layer = model.layers[-3]\n    else:\n        # Create a new model that outputs both the conv layer and final predictions\n        # We need to recreate the forward pass through the nested model\n        target_layer = last_conv_layer\n    \n    # Build a model that returns the outputs of the target layer and the final predictions\n    # Use a functional approach that works with nested models\n    grad_model = tf.keras.models.Model(\n        inputs=model.inputs,\n        outputs=[base_model_layer.output if base_model_layer else model.layers[-3].output, model.output]\n    )\n    \n    # Compute gradient of predicted class with respect to feature map\n    with tf.GradientTape() as tape:\n        conv_outputs, predictions = grad_model(img_array)\n        if pred_index is None:\n            pred_index = tf.argmax(predictions[0])\n        class_channel = predictions[:, pred_index]\n    \n    # Gradient of output with respect to conv layer\n    grads = tape.gradient(class_channel, conv_outputs)\n    \n    # Avoid division by zero\n    if grads is None:\n        # Fallback: return a simple heatmap\n        return np.ones((7, 7)) * 0.5\n    \n    # Mean intensity of gradient over specific feature map channel\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n    \n    # Multiply each channel by importance\n    conv_outputs = conv_outputs[0]\n    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n    \n    # Normalize heatmap\n    heatmap = tf.maximum(heatmap, 0)\n    max_val = tf.math.reduce_max(heatmap)\n    if max_val > 0:\n        heatmap = heatmap / max_val\n    \n    return heatmap.numpy()\n\n\ndef overlay_heatmap(heatmap, original_img, alpha=0.4, colormap=cv2.COLORMAP_JET):\n    \"\"\"\n    Overlay Grad-CAM heatmap on original image\n    \n    Args:\n        heatmap: Grad-CAM heatmap\n        original_img: Original PIL image\n        alpha: Transparency factor\n        colormap: OpenCV colormap\n    \n    Returns:\n        Overlaid image as bytes\n    \"\"\"\n    # Convert PIL image to numpy array\n    img_array = np.array(original_img)\n    \n    # Resize heatmap to match image size\n    heatmap = cv2.resize(heatmap, (img_array.shape[1], img_array.shape[0]))\n    \n    # Convert heatmap to RGB\n    heatmap = np.uint8(255 * heatmap)\n    heatmap = cv2.applyColorMap(heatmap, colormap)\n    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n    \n    # Overlay heatmap on original image\n    superimposed = cv2.addWeighted(img_array, 1 - alpha, heatmap, alpha, 0)\n    \n    # Convert to PIL Image and save to bytes\n    result_img = Image.fromarray(superimposed)\n    img_bytes = io.BytesIO()\n    result_img.save(img_bytes, format='PNG')\n    img_bytes.seek(0)\n    \n    return img_bytes\n\n\n@app.route('/register', methods=['GET', 'POST'])\ndef register():\n    \"\"\"User registration\"\"\"\n    if current_user.is_authenticated:\n        return redirect(url_for('index'))\n    \n    if request.method == 'POST':\n        username = request.form.get('username')\n        password = request.form.get('password')\n        confirm_password = request.form.get('confirm_password')\n        \n        if not username or not password:\n            flash('Username and password are required.', 'error')\n            return render_template('register.html')\n        \n        if password != confirm_password:\n            flash('Passwords do not match.', 'error')\n            return render_template('register.html')\n        \n        if len(password) < 6:\n            flash('Password must be at least 6 characters long.', 'error')\n            return render_template('register.html')\n        \n        if User.query.filter_by(username=username).first():\n            flash('Username already taken. Please choose another.', 'error')\n            return render_template('register.html')\n        \n        user = User(username=username)\n        user.set_password(password)\n        db.session.add(user)\n        db.session.commit()\n        \n        flash('Account created successfully! Please login.', 'success')\n        return redirect(url_for('login'))\n    \n    return render_template('register.html')\n\n\n@app.route('/login', methods=['GET', 'POST'])\ndef login():\n    \"\"\"User login\"\"\"\n    if current_user.is_authenticated:\n        return redirect(url_for('index'))\n    \n    if request.method == 'POST':\n        username = request.form.get('username')\n        password = request.form.get('password')\n        remember = request.form.get('remember') == 'yes'\n        \n        if not username or not password:\n            flash('Username and password are required.', 'error')\n            return render_template('login.html')\n        \n        user = User.query.filter_by(username=username).first()\n        \n        if user and user.check_password(password):\n            login_user(user, remember=remember)\n            flash('Logged in successfully!', 'success')\n            next_page = request.args.get('next')\n            return redirect(next_page) if next_page else redirect(url_for('index'))\n        else:\n            flash('Invalid username or password.', 'error')\n    \n    return render_template('login.html')\n\n\n@app.route('/logout')\n@login_required\ndef logout():\n    \"\"\"User logout\"\"\"\n    logout_user()\n    flash('Logged out successfully.', 'success')\n    return redirect(url_for('login'))\n\n\n@app.route('/')\n@login_required\ndef index():\n    \"\"\"Serve main page\"\"\"\n    return render_template('index.html')\n\n\n@app.route('/predict', methods=['POST'])\ndef predict():\n    \"\"\"\n    Predict if currency is genuine or fake\n    Returns JSON with prediction, confidence, and Grad-CAM visualization\n    \"\"\"\n    if 'file' not in request.files:\n        return jsonify({'error': 'No file uploaded'}), 400\n    \n    file = request.files['file']\n    \n    if file.filename == '':\n        return jsonify({'error': 'No file selected'}), 400\n    \n    if not allowed_file(file.filename):\n        return jsonify({'error': 'Invalid file type. Use PNG, JPG, or JPEG'}), 400\n    \n    try:\n        # Save uploaded file\n        filename = secure_filename(file.filename)\n        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n        file.save(filepath)\n        \n        # Preprocess image\n        img_array, original_img = preprocess_image(filepath)\n        \n        # Make prediction\n        predictions = model.predict(img_array, verbose=0)\n        \n        # Debug: Print raw predictions\n        print(f\"Raw predictions: {predictions[0]}\")\n        \n        # Class indices from flow_from_directory (alphabetical):\n        # 0 = 'fake', 1 = 'genuine'\n        # predictions[0] = [prob_fake, prob_genuine]\n        fake_prob = float(predictions[0][0]) * 100\n        genuine_prob = float(predictions[0][1]) * 100\n        \n        print(f\"Fake probability: {fake_prob:.2f}%, Genuine probability: {genuine_prob:.2f}%\")\n        \n        # Determine prediction based on which probability is higher\n        if genuine_prob > fake_prob:\n            predicted_class = 1  # Genuine\n            confidence = genuine_prob\n            print(\"Prediction: Genuine\")\n        else:\n            predicted_class = 0  # Fake\n            confidence = fake_prob\n            print(\"Prediction: Fake\")\n        \n        # Generate Grad-CAM heatmap\n        try:\n            heatmap = make_gradcam_heatmap(img_array, model, pred_index=predicted_class)\n            \n            # Create overlay image\n            gradcam_bytes = overlay_heatmap(heatmap, original_img)\n            \n            # Save Grad-CAM image\n            gradcam_filename = f'gradcam_{filename}'\n            gradcam_path = os.path.join(app.config['UPLOAD_FOLDER'], gradcam_filename)\n            with open(gradcam_path, 'wb') as f:\n                f.write(gradcam_bytes.read())\n            \n            gradcam_url = f'/gradcam/{gradcam_filename}'\n        except Exception as gradcam_error:\n            print(f\"Grad-CAM error: {str(gradcam_error)}\")\n            import traceback\n            traceback.print_exc()\n            gradcam_url = None\n        \n        # Prepare response\n        result = {\n            'prediction': class_names[predicted_class],\n            'confidence': round(confidence, 2),\n            'is_genuine': bool(predicted_class == 1),\n            'probabilities': {\n                'fake': round(fake_prob, 2),\n                'genuine': round(genuine_prob, 2)\n            },\n            'warning': 'This model was trained on synthetic data. Results may not be accurate for real currency.'\n        }\n        \n        if gradcam_url:\n            result['gradcam_image'] = gradcam_url\n        \n        return jsonify(result)\n    \n    except Exception as e:\n        print(f\"Prediction error: {str(e)}\")\n        import traceback\n        traceback.print_exc()\n        return jsonify({'error': str(e)}), 500\n\n\n@app.route('/gradcam/<filename>')\ndef get_gradcam(filename):\n    \"\"\"Serve Grad-CAM visualization image\"\"\"\n    filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n    if os.path.exists(filepath):\n        return send_file(filepath, mimetype='image/png')\n    return jsonify({'error': 'File not found'}), 404\n\n\n@app.route('/testing')\n@login_required\ndef testing():\n    \"\"\"Serve testing page with model information\"\"\"\n    return render_template('testing.html')\n\n\n@app.route('/model-info')\n@login_required\ndef model_info():\n    \"\"\"Return model information for testing\"\"\"\n    if model is None:\n        return jsonify({'error': 'Model not loaded'}), 500\n    \n    try:\n        # Get model summary\n        layer_info = []\n        for layer in model.layers:\n            layer_info.append({\n                'name': layer.name,\n                'type': layer.__class__.__name__,\n                'output_shape': str(layer.output_shape) if hasattr(layer, 'output_shape') else 'N/A'\n            })\n        \n        # Check if model is trained or demo\n        model_path = 'model/currency_detector.h5'\n        is_trained = os.path.exists(model_path)\n        \n        return jsonify({\n            'model_type': 'Trained Model' if is_trained else 'Demo Model (Random Weights)',\n            'total_layers': len(model.layers),\n            'layers': layer_info,\n            'input_shape': str(model.input_shape),\n            'output_shape': str(model.output_shape),\n            'class_names': class_names\n        })\n    except Exception as e:\n        return jsonify({'error': str(e)}), 500\n\n\nif __name__ == '__main__':\n    # Create database tables\n    with app.app_context():\n        db.create_all()\n        print(\"Database initialized successfully\")\n    \n    # Load model at startup\n    load_model_file()\n    \n    # Run Flask app\n    app.run(host='0.0.0.0', port=5000, debug=False)\n","size_bytes":15890},"CounterfeitGuard/train_model.py":{"content":"\"\"\"\nTraining script for Currency Detection Model\nThis is a sample script - you'll need to provide your own dataset\n\"\"\"\nimport os\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom model import create_model, create_data_generators, fine_tune_model\nimport matplotlib.pyplot as plt\n\n\ndef train_model(train_dir, val_dir, epochs=20, batch_size=32):\n    \"\"\"\n    Train the currency detection model\n    \n    Args:\n        train_dir: Directory with training data (subdirectories: fake/, genuine/)\n        val_dir: Directory with validation data (subdirectories: fake/, genuine/)\n        epochs: Number of training epochs\n        batch_size: Batch size for training\n    \n    Returns:\n        Trained model and training history\n    \"\"\"\n    print(\"Creating model...\")\n    model = create_model()\n    model.summary()\n    \n    print(\"\\nCreating data generators...\")\n    train_generator, val_generator = create_data_generators(\n        train_dir, val_dir, batch_size\n    )\n    \n    print(f\"\\nTraining samples: {train_generator.samples}\")\n    print(f\"Validation samples: {val_generator.samples}\")\n    print(f\"Classes: {train_generator.class_indices}\")\n    \n    # Callbacks\n    callbacks = [\n        keras.callbacks.ModelCheckpoint(\n            'model/currency_detector_best.h5',\n            monitor='val_accuracy',\n            save_best_only=True,\n            verbose=1\n        ),\n        keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=5,\n            restore_best_weights=True,\n            verbose=1\n        ),\n        keras.callbacks.ReduceLROnPlateau(\n            monitor='val_loss',\n            factor=0.5,\n            patience=3,\n            min_lr=1e-7,\n            verbose=1\n        )\n    ]\n    \n    print(\"\\n\" + \"=\"*50)\n    print(\"Starting training...\")\n    print(\"=\"*50 + \"\\n\")\n    \n    # Train model\n    history = model.fit(\n        train_generator,\n        epochs=epochs,\n        validation_data=val_generator,\n        callbacks=callbacks,\n        verbose=1\n    )\n    \n    # Fine-tune the model\n    print(\"\\n\" + \"=\"*50)\n    print(\"Fine-tuning model...\")\n    print(\"=\"*50 + \"\\n\")\n    \n    model = fine_tune_model(model)\n    \n    history_fine = model.fit(\n        train_generator,\n        epochs=10,\n        validation_data=val_generator,\n        callbacks=callbacks,\n        verbose=1\n    )\n    \n    # Save final model\n    model.save('model/currency_detector.h5')\n    print(\"\\nModel saved to model/currency_detector.h5\")\n    \n    # Evaluate on validation set\n    print(\"\\n\" + \"=\"*50)\n    print(\"Evaluating model...\")\n    print(\"=\"*50 + \"\\n\")\n    \n    val_loss, val_accuracy = model.evaluate(val_generator)\n    print(f\"\\nValidation Accuracy: {val_accuracy*100:.2f}%\")\n    print(f\"Validation Loss: {val_loss:.4f}\")\n    \n    # Plot training history\n    plot_training_history(history, history_fine)\n    \n    return model, history\n\n\ndef plot_training_history(history, history_fine=None):\n    \"\"\"Plot training and validation accuracy/loss\"\"\"\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n    \n    # Plot accuracy\n    ax1.plot(history.history['accuracy'], label='Train Accuracy')\n    ax1.plot(history.history['val_accuracy'], label='Val Accuracy')\n    \n    if history_fine:\n        offset = len(history.history['accuracy'])\n        ax1.plot(range(offset, offset + len(history_fine.history['accuracy'])), \n                 history_fine.history['accuracy'], label='Train Accuracy (Fine-tune)')\n        ax1.plot(range(offset, offset + len(history_fine.history['val_accuracy'])), \n                 history_fine.history['val_accuracy'], label='Val Accuracy (Fine-tune)')\n    \n    ax1.set_xlabel('Epoch')\n    ax1.set_ylabel('Accuracy')\n    ax1.set_title('Model Accuracy')\n    ax1.legend()\n    ax1.grid(True)\n    \n    # Plot loss\n    ax2.plot(history.history['loss'], label='Train Loss')\n    ax2.plot(history.history['val_loss'], label='Val Loss')\n    \n    if history_fine:\n        offset = len(history.history['loss'])\n        ax2.plot(range(offset, offset + len(history_fine.history['loss'])), \n                 history_fine.history['loss'], label='Train Loss (Fine-tune)')\n        ax2.plot(range(offset, offset + len(history_fine.history['val_loss'])), \n                 history_fine.history['val_loss'], label='Val Loss (Fine-tune)')\n    \n    ax2.set_xlabel('Epoch')\n    ax2.set_ylabel('Loss')\n    ax2.set_title('Model Loss')\n    ax2.legend()\n    ax2.grid(True)\n    \n    plt.tight_layout()\n    plt.savefig('model/training_history.png', dpi=150)\n    print(\"\\nTraining history plot saved to model/training_history.png\")\n\n\ndef create_demo_model():\n    \"\"\"\n    Create and save a demo model with random weights\n    This is just for demonstration - train with real data for actual use\n    \"\"\"\n    print(\"Creating demo model...\")\n    model = create_model()\n    \n    # Save demo model\n    os.makedirs('model', exist_ok=True)\n    model.save('model/currency_detector.h5')\n    print(\"Demo model saved to model/currency_detector.h5\")\n    print(\"\\nWARNING: This is an untrained model with random weights!\")\n    print(\"For real use, train the model with actual currency dataset.\")\n\n\nif __name__ == '__main__':\n    # Check if dataset directories exist\n    train_dir = 'dataset/train'\n    val_dir = 'dataset/val'\n    \n    if os.path.exists(train_dir) and os.path.exists(val_dir):\n        # Train with actual dataset\n        print(\"Dataset found. Starting training...\")\n        print(f\"Train directory: {train_dir}\")\n        print(f\"Validation directory: {val_dir}\")\n        print(\"\\nExpected structure:\")\n        print(\"  dataset/train/fake/\")\n        print(\"  dataset/train/genuine/\")\n        print(\"  dataset/val/fake/\")\n        print(\"  dataset/val/genuine/\\n\")\n        \n        model, history = train_model(train_dir, val_dir, epochs=20)\n    else:\n        # Create demo model\n        print(\"No dataset found.\")\n        print(f\"Expected directories: {train_dir}, {val_dir}\")\n        print(\"\\nCreating demo model for testing purposes...\")\n        create_demo_model()\n","size_bytes":5991},"create_indian_currency_dataset.py":{"content":"\n\"\"\"\nCreate Indian Currency Dataset from Test Images\nUses actual fake and genuine currency images for training\n\"\"\"\nimport os\nimport shutil\nfrom pathlib import Path\n\ndef create_dataset():\n    \"\"\"Create train/val split from Test Images directory\"\"\"\n    \n    print(\"=\"*70)\n    print(\"CREATING INDIAN CURRENCY DATASET WITH ACTUAL IMAGES\")\n    print(\"=\"*70)\n    \n    # Source directories\n    genuine_source = \"Test Images/genuine\"\n    fake_source = \"Test Images/fake\"\n    \n    # Destination directories\n    dataset_root = \"indian_currency_dataset\"\n    train_dir = os.path.join(dataset_root, \"train\")\n    val_dir = os.path.join(dataset_root, \"val\")\n    \n    # Create directory structure\n    for split in ['train', 'val']:\n        for class_name in ['fake', 'genuine']:\n            os.makedirs(os.path.join(dataset_root, split, class_name), exist_ok=True)\n    \n    # Get all images\n    genuine_images = sorted([f for f in os.listdir(genuine_source) if f.endswith(('.jpg', '.png', '.jpeg'))])\n    fake_images = sorted([f for f in os.listdir(fake_source) if f.endswith(('.jpg', '.png', '.jpeg'))])\n    \n    print(f\"\\nFound {len(genuine_images)} genuine currency images\")\n    print(f\"Found {len(fake_images)} fake currency images\")\n    \n    # Split: 80% train, 20% validation\n    genuine_split = int(len(genuine_images) * 0.8)\n    fake_split = int(len(fake_images) * 0.8)\n    \n    genuine_train = genuine_images[:genuine_split]\n    genuine_val = genuine_images[genuine_split:]\n    \n    fake_train = fake_images[:fake_split]\n    fake_val = fake_images[fake_split:]\n    \n    print(f\"\\nTrain set: {len(genuine_train)} genuine + {len(fake_train)} fake\")\n    print(f\"Val set: {len(genuine_val)} genuine + {len(fake_val)} fake\")\n    \n    print(\"\\nCopying images to dataset...\")\n    \n    # Copy training images\n    for img in genuine_train:\n        src = os.path.join(genuine_source, img)\n        dst = os.path.join(train_dir, 'genuine', img)\n        shutil.copy2(src, dst)\n    \n    for img in fake_train:\n        src = os.path.join(fake_source, img)\n        dst = os.path.join(train_dir, 'fake', img)\n        shutil.copy2(src, dst)\n    \n    # Copy validation images\n    for img in genuine_val:\n        src = os.path.join(genuine_source, img)\n        dst = os.path.join(val_dir, 'genuine', img)\n        shutil.copy2(src, dst)\n    \n    for img in fake_val:\n        src = os.path.join(fake_source, img)\n        dst = os.path.join(val_dir, 'fake', img)\n        shutil.copy2(src, dst)\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"DATASET CREATED SUCCESSFULLY!\")\n    print(\"=\"*70)\n    \n    print(f\"\\nDataset structure:\")\n    print(f\"  {train_dir}/fake/ - {len(fake_train)} images\")\n    print(f\"  {train_dir}/genuine/ - {len(genuine_train)} images\")\n    print(f\"  {val_dir}/fake/ - {len(fake_val)} images\")\n    print(f\"  {val_dir}/genuine/ - {len(genuine_val)} images\")\n    print(\"=\"*70)\n    \n    print(\"\\nNext step: Run 'python train_indian_currency_model.py' to train the model\")\n    print(\"=\"*70)\n\nif __name__ == '__main__':\n    create_dataset()\n","size_bytes":3022},"CounterfeitGuard/add_user.py":{"content":"#!/usr/bin/env python\n\"\"\"Simple script to create a user account without loading the model\"\"\"\nimport os\nimport sys\nfrom flask import Flask\nfrom flask_sqlalchemy import SQLAlchemy\nfrom flask_login import UserMixin\nfrom werkzeug.security import generate_password_hash\nfrom sqlalchemy.orm import DeclarativeBase\n\nclass Base(DeclarativeBase):\n    pass\n\ndb = SQLAlchemy(model_class=Base)\napp = Flask(__name__)\napp.config['SECRET_KEY'] = os.environ.get('SECRET_KEY', 'dev-secret-key-change-in-production')\napp.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///currency_detector.db'\napp.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False\n\ndb.init_app(app)\n\nclass User(UserMixin, db.Model):\n    id = db.Column(db.Integer, primary_key=True)\n    username = db.Column(db.String(80), unique=True, nullable=False)\n    password_hash = db.Column(db.String(200), nullable=False)\n\nwith app.app_context():\n    # Create a demo user\n    username = \"admin\"\n    password = \"admin123\"\n    \n    # Check if user already exists\n    existing_user = User.query.filter_by(username=username).first()\n    if existing_user:\n        print(f\"User '{username}' already exists!\")\n    else:\n        # Create new user\n        user = User(username=username)\n        user.password_hash = generate_password_hash(password)\n        db.session.add(user)\n        db.session.commit()\n        print(f\"User '{username}' created successfully!\")\n    \n    print(f\"\\nLogin credentials:\")\n    print(f\"Username: {username}\")\n    print(f\"Password: {password}\")\n","size_bytes":1500}},"version":2}